---
layout: post
title: "Paper Surveyä¹‹â€”â€”Awesome Diffusion-based SLAM"
date:   2025-03-20
tags: [SLAM, Deep Learning]
comments: true
author: kwanwaipang
toc: false #true
---


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# å¼•è¨€
ä¹‹å‰åšå®¢åœ¨å¯¹Transformer-based SLAMè¿›è¡Œè°ƒç ”çš„æ—¶å€™ï¼Œæ— æ„ä¸­å‘ç°ç«Ÿç„¶è¿˜è¦åŸºäºDiffusionçš„SLAMç›¸å…³çš„å·¥ä½œï¼Œä¸ºæ­¤é’ˆå¯¹å…¶è¿›è¡Œè°ƒç ”ï¼Œçœ‹çœ‹Diffusionåœ¨SLAMã€å…‰æµã€æ·±åº¦ä¼°è®¡ã€æ•°æ®å…³è”ã€å§¿æ€ä¼°è®¡ç­‰ç›¸å…³ä»»åŠ¡ä¸Šè¡¨ç°å¦‚ä½•~

æœ¬åšæ–‡ä»…ä¾›æœ¬äººå­¦ä¹ è®°å½•ç”¨~

* ç›®å½•
{:toc}


å…¶ä»–ç›¸å…³é“¾æ¥ï¼š

* [What is Diffusion?](https://kwanwaipang.github.io/Diffusion/)
* Learning-based VO,VIO,IOï¼š[Paper List](https://github.com/KwanWaiPang/Awesome-Learning-based-VO-VIO) ä»¥åŠ[åšå®¢](https://kwanwaipang.github.io/Learning-based-VO-VIO/)
* Transformer-based SLAMï¼š[Paper List](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM) ä»¥åŠ[åšå®¢](https://kwanwaipang.github.io/Transformer_SLAM/)
* NeRF-based SLAMï¼š[åšå®¢](https://kwanwaipang.github.io/Awesome-NeRF-SLAM/)
* 3DGS-based SLAM: [åšå®¢](https://kwanwaipang.github.io/File/Blogs/Poster/survey_3DGS_SLAM.html)


# Paper List

* æ³¨æ„ï¼Œæ­¤å¤„éæœ€æ–°ç‰ˆï¼Œä»…ä»…æ˜¯å†™æ­¤åšå®¢çš„æ—¶å€™çš„è®°å½•
* Keep update the paper list in: [Awesome-Diffusion-based-SLAM](https://github.com/KwanWaiPang/Awesome-Diffusion-based-SLAM)


## Matching

or data association, or correspondence

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[MATCHA: Towards Matching Anything](https://arxiv.org/pdf/2501.14945)|---|SD+DINOv2|
|2024|`CVPR`|[Sd4match: Learning to prompt stable diffusion model for semantic matching](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_SD4Match_Learning_to_Prompt_Stable_Diffusion_Model_for_Semantic_Matching_CVPR_2024_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/ActiveVisionLab/SD4Match.svg)](https://github.com/ActiveVisionLab/SD4Match)|[website](https://sd4match.active.vision/)|
|2023|`NIPS`|[Emergent correspondence from image diffusion](https://proceedings.neurips.cc/paper_files/paper/2023/file/0503f5dce343a1d06d16ba103dd52db1-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/Tsingularity/dift.svg)](https://github.com/Tsingularity/dift)|[website](https://diffusionfeatures.github.io/)<br>DIFT|
|2023|`NIPS`|[A tale of two features: Stable diffusion complements dino for zero-shot semantic correspondence](https://proceedings.neurips.cc/paper_files/paper/2023/file/8e9bdc23f169a05ea9b72ccef4574551-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/Junyi42/sd-dino.svg)](https://github.com/Junyi42/sd-dino)|[website](https://sd-complements-dino.github.io/)<br>SD+DINO|
|2023|`NIPS`|[Diffusion hyperfeatures: Searching through time and space for semantic correspondence](https://proceedings.neurips.cc/paper_files/paper/2023/file/942032b61720a3fd64897efe46237c81-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/diffusion-hyperfeatures/diffusion_hyperfeatures.svg)](https://github.com/diffusion-hyperfeatures/diffusion_hyperfeatures)|[website](https://diffusion-hyperfeatures.github.io/)<br>DHF|


## Depth Estimation

or 3D reconstruction

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[Bolt3D: Generating 3D Scenes in Seconds](https://arxiv.org/pdf/2503.14445)|---|[website](https://szymanowiczs.github.io/bolt3d)|
|2025|`arXiv`|[Stable Virtual Camera: Generative View Synthesis with Diffusion Models](https://arxiv.org/pdf/2503.14489)|[![Github stars](https://img.shields.io/github/stars/Stability-AI/stable-virtual-camera.svg)](https://github.com/Stability-AI/stable-virtual-camera) |---|
|2025|`CVPR`|[Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models](https://arxiv.org/pdf/2503.01774?)|---|[website](https://research.nvidia.com/labs/toronto-ai/difix3d/)|
|2025|`CVPR`|[Multi-view Reconstruction via SfM-guided Monocular Depth Estimation](https://arxiv.org/pdf/2503.14483)|[![Github stars](https://img.shields.io/github/stars/zju3dv/Murre.svg)](https://github.com/zju3dv/Murre)|[website](https://zju3dv.github.io/murre/)|
|2025|`CVPR`|[Align3r: Aligned monocular depth estimation for dynamic videos](https://arxiv.org/pdf/2412.03079)|[![Github stars](https://img.shields.io/github/stars/jiah-cloud/Align3R.svg)](https://github.com/jiah-cloud/Align3R)|---|
|2024|`ECCV`|[Diffusiondepth: Diffusion denoising approach for monocular depth estimation](https://arxiv.org/pdf/2303.05021)|[![Github stars](https://img.shields.io/github/stars/duanyiqun/DiffusionDepth.svg)](https://github.com/duanyiqun/DiffusionDepth)|[website](https://igl-hkust.github.io/Align3R.github.io/)|
|2023|`NIPS`|[The surprising effectiveness of diffusion models for optical flow and monocular depth estimation](https://proceedings.neurips.cc/paper_files/paper/2023/file/7c119415672ae2186e17d492e1d5da2f-Paper-Conference.pdf)|---|[website](https://diffusion-vision.github.io/)|
|2023|`arXiv`|[Monocular depth estimation using diffusion models](https://arxiv.org/pdf/2302.14816)|---|[website](https://depth-gen.github.io/)| 


## Pose Estimation

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2023|`ICCV`|[Posediffusion: Solving pose estimation via diffusion-aided bundle adjustment](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/facebookresearch/PoseDiffusion.svg)](https://github.com/facebookresearch/PoseDiffusion)|[website](https://posediffusion.github.io/)|




* Some basic paper for Diffusion Model

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2022|`CVPR`|[High-resolution image synthesis with latent diffusion models](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/CompVis/latent-diffusion.svg)](https://github.com/CompVis/latent-diffusion)|stable diffusion|
|2021|`NIPS`|[Diffusion models beat gans on image synthesis](https://proceedings.neurips.cc/paper_files/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf)|---|---|
|2020|`ICLR`|[Denoising diffusion implicit models](https://arxiv.org/pdf/2010.02502)|---|DDIM|
|2020|`NIPS`|[Denoising diffusion probabilistic models](https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf)|[![Github stars](https://img.shields.io/github/stars/hojonathanho/diffusion.svg)](https://github.com/hojonathanho/diffusion)|DDPM|




# Paper Reading
æ¥ä¸‹æ¥é‡ç‚¹é˜…è¯»å‡ ç¯‡è®ºæ–‡

## MATCHA: Towards Matching Anything

å»ºç«‹äºinsights:`diffusion model features can encode multiple correspondence types`,ä½œè€…æå‡ºåŸºäºdiffusion model çš„MATCHAï¼Œå¹¶è¿›ä¸€æ­¥é€šè¿‡åŸºäºæ³¨æ„åŠ›çš„åŠ¨æ€èåˆé«˜çº§è¯­ä¹‰å’Œä½çº§å‡ ä½•ç‰¹å¾ï¼Œè¿›è€Œè·å–å…·æœ‰ä»£è¡¨æ€§çš„ã€é€šç”¨çš„ä»¥åŠå¼ºé²æ£’æ€§çš„ç‰¹å¾ã€‚

è¿™é‡Œæ‰€è°“çš„ç‰¹å¾åŒ¹é…åŒ…æ‹¬äº†å‡ ä½•( geometric)ã€è¯­ä¹‰(semantic)ã€æ—¶é—´ï¼ˆtemporalï¼‰ç­‰å¤šä¸ªç»´åº¦çš„ç‰¹å¾åŒ¹é…ï¼Œä¹Ÿå°±æ˜¯åŒä¸€ä¸ªæ¡†æ¶,åªéœ€è¦å­¦ä¹ å•ä¸ªç‰¹å¾çš„æè¿°å­å³å¯å®Œæˆè¿™ä¸‰ä¸ªä»»åŠ¡ä¸‹çš„ç‰¹å¾åŒ¹é…
<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250320151734.png" width="60%" />
<figcaption>  
</figcaption>
</div>

MATCHAæ•´åˆäº†æ¥è‡ªäºDINO V2(ã€Š[Dinov2: Learning robust visual features without supervision](https://arxiv.org/pdf/2304.07193)ã€‹)çš„ç‰¹å¾æ¥è¿›ä¸€æ­¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
å…³äºè¿™ç‚¹ï¼Œåº”è¯¥æ˜¯ç”±äºç¼ºä¹æ¥è‡ªè¯­ä¹‰ä»¥åŠå‡ ä½•çš„è¶³å¤Ÿçš„çœŸå®æ•°æ®ï¼Œå› æ­¤ä½œè€…ç›´æ¥ç”¨äº†é¢„è®­ç»ƒçš„transformeræ¨¡å‹æ¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250320153747.png" width="60%" />
<figcaption>  
</figcaption>
</div>
DINO V2æä¾›çš„åº”è¯¥æ˜¯ semantic knowledge, DIFTæä¾›çš„semanticå’Œgeometricä¿¡æ¯ï¼Œåœ¨å›¾ä¾‹ä¸Šå…·æœ‰äº’è¡¥æ€§ï¼Œè€ŒMATCHAåˆ™æ˜¯åˆ©ç”¨äº†è¿™ä¸‰ç§åŸºæœ¬çš„ç‰¹å¾æ¥æä¾›æ›´å¯é çš„ç‰¹å¾åŒ¹é…ã€‚

å…¶æ¡†æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚é¦–å…ˆé€šè¿‡stable diffusionæ¥åˆ†åˆ«æå–è¯­ä¹‰ä»¥åŠå‡ ä½•ç‰¹å¾ï¼Œå¹¶é€šè¿‡transformeræ¥èåˆä¸€èµ·ï¼Œå†é€šè¿‡å¯¹åº”çš„çœŸå€¼æ¥åˆ†åˆ«è®­ç»ƒã€‚
ç„¶åæŠŠæ¥è‡ªäºDINOv2çš„ç‰¹å¾ä¸stable diffusionçš„è¯­ä¹‰åŠå‡ ä½•ç‰¹å¾concatenateåˆ°ä¸€èµ·ï¼Œä½œä¸ºmatching anythingçš„ç‰¹å¾.
è¯´å®è¯ï¼Œè¿™ä¸ªæ¡†æ¶æ„Ÿè§‰æœ‰ç‚¹å¤§åŠ›å‡ºå¥‡è¿¹çš„æ„å‘³ï¼Œstable diffusion+transformer+DINOv2å…¨éƒ¨æŸ”åˆ°ä¸€å—,è€Œå…¶ä¸­çš„`stable diffusion+transformer`åˆ™æ˜¯DIFTï¼Œå› æ­¤ç®—æ˜¯DIFT+DINOv2

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250320154105.png" width="60%" />
<figcaption>  
</figcaption>
</div>

ä¸‹é¢çœ‹çœ‹å®éªŒæ•ˆæœ

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162153.png" width="80%" />
<figcaption>  
</figcaption>
</div>
çº¢è‰²åº”è¯¥æ˜¯è¯¯åŒ¹é…çš„ï¼Œä½†æ˜¯å“ªæ€•æ˜¯å…­å¼ å›¾ï¼Œæ„Ÿè§‰ä¸Šä¹Ÿå°±åªæœ‰ä¸¤å¼ MATCHAæ²¡æœ‰è¯¯åŒ¹é…ï¼Œå…¶ä»–å¯¹æ¯”æ•ˆæœä¸ªäººè§‰å¾—ä¸å¤ªæ˜æ˜¾ã€‚æ¯•ç«Ÿè€ƒè™‘åˆ°æ˜¯æŠŠå‰ä¸¤è€…èåˆåˆ°ä¸€èµ·çš„å¤§æ¨¡å‹ğŸ˜‚

å½“ç„¶ï¼Œä½œè€…ä¹Ÿæœ‰è·ŸMASt3Rç­‰SOTAå¯¹æ¯”çš„å‡ ä½•ã€è¯­ä¹‰ã€è·Ÿè¸ªç­‰åŒ¹é…çš„æ•ˆæœï¼ˆå¤ªå¤šäº†ï¼Œå°±éšæœºåˆ—å‡ºä¸€äº›ï¼Œæ›´å¤šçš„è¯·è§åŸæ–‡~ï¼‰ã€‚
ä¸‹å›¾çš„ç»“æœéƒ½æ˜¯RANSACè¾“å‡ºçš„inliers
<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162627.png" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162710.png" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

è¯­ä¹‰åŒ¹é…çš„æ•ˆæœ

<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162840.png" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162852.png" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>


## Emergent correspondence from image diffusion

è¿™ç¯‡è®ºæ–‡å°±æ˜¯DIFTï¼Œä¹Ÿå°±æ˜¯åˆ©ç”¨diffusionæ¥è·å–å›¾åƒä¹‹é—´çš„correspondenceï¼ŒåŒæ ·åœ°ï¼Œä¹Ÿæ˜¯é’ˆå¯¹semantic, geometric, å’Œ temporalæ•°æ®å…³è”