---
layout: post
title: "Paper Surveyä¹‹â€”â€”Awesome Diffusion-based SLAM"
date:   2025-03-20
tags: [SLAM, Deep Learning]
comments: true
author: kwanwaipang
toc: false #true
---


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# å¼•è¨€
ä¹‹å‰åšå®¢åœ¨å¯¹Transformer-based SLAMè¿›è¡Œè°ƒç ”çš„æ—¶å€™ï¼Œæ— æ„ä¸­å‘ç°ç«Ÿç„¶è¿˜è¦åŸºäºDiffusionçš„SLAMç›¸å…³çš„å·¥ä½œï¼Œä¸ºæ­¤é’ˆå¯¹å…¶è¿›è¡Œè°ƒç ”ï¼Œçœ‹çœ‹Diffusionåœ¨SLAMã€å…‰æµã€æ·±åº¦ä¼°è®¡ã€æ•°æ®å…³è”ã€å§¿æ€ä¼°è®¡ç­‰ç›¸å…³ä»»åŠ¡ä¸Šè¡¨ç°å¦‚ä½•~

æœ¬åšæ–‡ä»…ä¾›æœ¬äººå­¦ä¹ è®°å½•ç”¨~

* ç›®å½•
{:toc}


å…¶ä»–ç›¸å…³é“¾æ¥ï¼š

* [What is Diffusion?](https://kwanwaipang.github.io/Diffusion/)
* Learning-based VO,VIO,IOï¼š[Paper List](https://github.com/KwanWaiPang/Awesome-Learning-based-VO-VIO) ä»¥åŠ[åšå®¢](https://kwanwaipang.github.io/Learning-based-VO-VIO/)
* Transformer-based SLAMï¼š[Paper List](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM) ä»¥åŠ[åšå®¢](https://kwanwaipang.github.io/Transformer_SLAM/)
* NeRF-based SLAMï¼š[åšå®¢](https://kwanwaipang.github.io/Awesome-NeRF-SLAM/)
* 3DGS-based SLAM: [åšå®¢](https://kwanwaipang.github.io/File/Blogs/Poster/survey_3DGS_SLAM.html)


# Paper List

* æ³¨æ„ï¼Œæ­¤å¤„éæœ€æ–°ç‰ˆï¼Œä»…ä»…æ˜¯å†™æ­¤åšå®¢çš„æ—¶å€™çš„è®°å½•
* Keep update the paper list in: [Awesome-Diffusion-based-SLAM](https://github.com/KwanWaiPang/Awesome-Diffusion-based-SLAM)


## Matching

or data association, or correspondence

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[MATCHA: Towards Matching Anything](https://arxiv.org/pdf/2501.14945)|---|SD+DINOv2|
|2024|`CVPR`|[Sd4match: Learning to prompt stable diffusion model for semantic matching](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_SD4Match_Learning_to_Prompt_Stable_Diffusion_Model_for_Semantic_Matching_CVPR_2024_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/ActiveVisionLab/SD4Match.svg)](https://github.com/ActiveVisionLab/SD4Match)|[website](https://sd4match.active.vision/)|
|2023|`NIPS`|[Emergent correspondence from image diffusion](https://proceedings.neurips.cc/paper_files/paper/2023/file/0503f5dce343a1d06d16ba103dd52db1-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/Tsingularity/dift.svg)](https://github.com/Tsingularity/dift)|[website](https://diffusionfeatures.github.io/)<br>DIFT|
|2023|`NIPS`|[A tale of two features: Stable diffusion complements dino for zero-shot semantic correspondence](https://proceedings.neurips.cc/paper_files/paper/2023/file/8e9bdc23f169a05ea9b72ccef4574551-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/Junyi42/sd-dino.svg)](https://github.com/Junyi42/sd-dino)|[website](https://sd-complements-dino.github.io/)<br>SD+DINO|
|2023|`NIPS`|[Diffusion hyperfeatures: Searching through time and space for semantic correspondence](https://proceedings.neurips.cc/paper_files/paper/2023/file/942032b61720a3fd64897efe46237c81-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/diffusion-hyperfeatures/diffusion_hyperfeatures.svg)](https://github.com/diffusion-hyperfeatures/diffusion_hyperfeatures)|[website](https://diffusion-hyperfeatures.github.io/)<br>DHF|


## Depth Estimation

or 3D reconstruction

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[Bolt3D: Generating 3D Scenes in Seconds](https://arxiv.org/pdf/2503.14445)|---|[website](https://szymanowiczs.github.io/bolt3d)|
|2025|`arXiv`|[Stable Virtual Camera: Generative View Synthesis with Diffusion Models](https://arxiv.org/pdf/2503.14489)|[![Github stars](https://img.shields.io/github/stars/Stability-AI/stable-virtual-camera.svg)](https://github.com/Stability-AI/stable-virtual-camera) |---|
|2025|`CVPR`|[Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models](https://arxiv.org/pdf/2503.01774?)|---|[website](https://research.nvidia.com/labs/toronto-ai/difix3d/)|
|2025|`CVPR`|[Multi-view Reconstruction via SfM-guided Monocular Depth Estimation](https://arxiv.org/pdf/2503.14483)|[![Github stars](https://img.shields.io/github/stars/zju3dv/Murre.svg)](https://github.com/zju3dv/Murre)|[website](https://zju3dv.github.io/murre/)|
|2025|`CVPR`|[Align3r: Aligned monocular depth estimation for dynamic videos](https://arxiv.org/pdf/2412.03079)|[![Github stars](https://img.shields.io/github/stars/jiah-cloud/Align3R.svg)](https://github.com/jiah-cloud/Align3R)|---|
|2024|`ECCV`|[Diffusiondepth: Diffusion denoising approach for monocular depth estimation](https://arxiv.org/pdf/2303.05021)|[![Github stars](https://img.shields.io/github/stars/duanyiqun/DiffusionDepth.svg)](https://github.com/duanyiqun/DiffusionDepth)|[website](https://igl-hkust.github.io/Align3R.github.io/)|
|2023|`NIPS`|[The surprising effectiveness of diffusion models for optical flow and monocular depth estimation](https://proceedings.neurips.cc/paper_files/paper/2023/file/7c119415672ae2186e17d492e1d5da2f-Paper-Conference.pdf)|---|[website](https://diffusion-vision.github.io/)|
|2023|`arXiv`|[Monocular depth estimation using diffusion models](https://arxiv.org/pdf/2302.14816)|---|[website](https://depth-gen.github.io/)| 


## Pose Estimation

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2023|`ICCV`|[Posediffusion: Solving pose estimation via diffusion-aided bundle adjustment](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/facebookresearch/PoseDiffusion.svg)](https://github.com/facebookresearch/PoseDiffusion)|[website](https://posediffusion.github.io/)|




* Some basic paper for Diffusion Model

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2022|`CVPR`|[High-resolution image synthesis with latent diffusion models](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/CompVis/latent-diffusion.svg)](https://github.com/CompVis/latent-diffusion)|stable diffusion|
|2021|`NIPS`|[Diffusion models beat gans on image synthesis](https://proceedings.neurips.cc/paper_files/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf)|---|Ablated Diffusion Model(ADM)|
|2020|`ICLR`|[Denoising diffusion implicit models](https://arxiv.org/pdf/2010.02502)|---|DDIM|
|2020|`NIPS`|[Denoising diffusion probabilistic models](https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf)|[![Github stars](https://img.shields.io/github/stars/hojonathanho/diffusion.svg)](https://github.com/hojonathanho/diffusion)|DDPM|




# Paper Reading
æ¥ä¸‹æ¥é‡ç‚¹é˜…è¯»å‡ ç¯‡è®ºæ–‡

## MATCHA: Towards Matching Anything

å»ºç«‹äºinsights:`diffusion model features can encode multiple correspondence types`,ä½œè€…æå‡ºåŸºäºdiffusion model çš„MATCHAï¼Œå¹¶è¿›ä¸€æ­¥é€šè¿‡åŸºäºæ³¨æ„åŠ›çš„åŠ¨æ€èåˆé«˜çº§è¯­ä¹‰å’Œä½çº§å‡ ä½•ç‰¹å¾ï¼Œè¿›è€Œè·å–å…·æœ‰ä»£è¡¨æ€§çš„ã€é€šç”¨çš„ä»¥åŠå¼ºé²æ£’æ€§çš„ç‰¹å¾ã€‚

è¿™é‡Œæ‰€è°“çš„ç‰¹å¾åŒ¹é…åŒ…æ‹¬äº†å‡ ä½•( geometric)ã€è¯­ä¹‰(semantic)ã€æ—¶é—´ï¼ˆtemporalï¼‰ç­‰å¤šä¸ªç»´åº¦çš„ç‰¹å¾åŒ¹é…ï¼Œä¹Ÿå°±æ˜¯åŒä¸€ä¸ªæ¡†æ¶,åªéœ€è¦å­¦ä¹ å•ä¸ªç‰¹å¾çš„æè¿°å­å³å¯å®Œæˆè¿™ä¸‰ä¸ªä»»åŠ¡ä¸‹çš„ç‰¹å¾åŒ¹é…
<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250320151734.png" width="60%" />
<figcaption>  
</figcaption>
</div>

MATCHAæ•´åˆäº†æ¥è‡ªäºDINO V2(ã€Š[Dinov2: Learning robust visual features without supervision](https://arxiv.org/pdf/2304.07193)ã€‹)çš„ç‰¹å¾æ¥è¿›ä¸€æ­¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
å…³äºè¿™ç‚¹ï¼Œåº”è¯¥æ˜¯ç”±äºç¼ºä¹æ¥è‡ªè¯­ä¹‰ä»¥åŠå‡ ä½•çš„è¶³å¤Ÿçš„çœŸå®æ•°æ®ï¼Œå› æ­¤ä½œè€…ç›´æ¥ç”¨äº†é¢„è®­ç»ƒçš„transformeræ¨¡å‹æ¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250320153747.png" width="60%" />
<figcaption>  
</figcaption>
</div>
DINO V2æä¾›çš„åº”è¯¥æ˜¯ semantic knowledge, DIFTæä¾›çš„semanticå’Œgeometricä¿¡æ¯ï¼Œåœ¨å›¾ä¾‹ä¸Šå…·æœ‰äº’è¡¥æ€§ï¼Œè€ŒMATCHAåˆ™æ˜¯åˆ©ç”¨äº†è¿™ä¸‰ç§åŸºæœ¬çš„ç‰¹å¾æ¥æä¾›æ›´å¯é çš„ç‰¹å¾åŒ¹é…ã€‚

å…¶æ¡†æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚é¦–å…ˆé€šè¿‡stable diffusionæ¥åˆ†åˆ«æå–è¯­ä¹‰ä»¥åŠå‡ ä½•ç‰¹å¾ï¼Œå¹¶é€šè¿‡transformeræ¥èåˆä¸€èµ·ï¼Œå†é€šè¿‡å¯¹åº”çš„çœŸå€¼æ¥åˆ†åˆ«è®­ç»ƒã€‚
ç„¶åæŠŠæ¥è‡ªäºDINOv2çš„ç‰¹å¾ä¸stable diffusionçš„è¯­ä¹‰åŠå‡ ä½•ç‰¹å¾concatenateåˆ°ä¸€èµ·ï¼Œä½œä¸ºmatching anythingçš„ç‰¹å¾.
è¯´å®è¯ï¼Œè¿™ä¸ªæ¡†æ¶æ„Ÿè§‰æœ‰ç‚¹å¤§åŠ›å‡ºå¥‡è¿¹çš„æ„å‘³ï¼Œstable diffusion+transformer+DINOv2å…¨éƒ¨æŸ”åˆ°ä¸€å—,è€Œå…¶ä¸­çš„`stable diffusion+transformer`åˆ™æ˜¯DIFTï¼Œå› æ­¤ç®—æ˜¯DIFT+DINOv2

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250320154105.png" width="60%" />
<figcaption>  
</figcaption>
</div>

ä¸‹é¢çœ‹çœ‹å®éªŒæ•ˆæœ

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162153.png" width="80%" />
<figcaption>  
</figcaption>
</div>
çº¢è‰²åº”è¯¥æ˜¯è¯¯åŒ¹é…çš„ï¼Œä½†æ˜¯å“ªæ€•æ˜¯å…­å¼ å›¾ï¼Œæ„Ÿè§‰ä¸Šä¹Ÿå°±åªæœ‰ä¸¤å¼ MATCHAæ²¡æœ‰è¯¯åŒ¹é…ï¼Œå…¶ä»–å¯¹æ¯”æ•ˆæœä¸ªäººè§‰å¾—ä¸å¤ªæ˜æ˜¾ã€‚æ¯•ç«Ÿè€ƒè™‘åˆ°æ˜¯æŠŠå‰ä¸¤è€…èåˆåˆ°ä¸€èµ·çš„å¤§æ¨¡å‹ğŸ˜‚

å½“ç„¶ï¼Œä½œè€…ä¹Ÿæœ‰è·ŸMASt3Rç­‰SOTAå¯¹æ¯”çš„å‡ ä½•ã€è¯­ä¹‰ã€è·Ÿè¸ªç­‰åŒ¹é…çš„æ•ˆæœï¼ˆå¤ªå¤šäº†ï¼Œå°±éšæœºåˆ—å‡ºä¸€äº›ï¼Œæ›´å¤šçš„è¯·è§åŸæ–‡~ï¼‰ã€‚
ä¸‹å›¾çš„ç»“æœéƒ½æ˜¯RANSACè¾“å‡ºçš„inliers
<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162627.png" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162710.png" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

è¯­ä¹‰åŒ¹é…çš„æ•ˆæœ

<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162840.png" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="../images/å¾®ä¿¡æˆªå›¾_20250320162852.png" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>


## Emergent correspondence from image diffusion

è¿™ç¯‡è®ºæ–‡å°±æ˜¯DIFT(DIffusion FeaTures)ï¼Œä¹Ÿå°±æ˜¯åˆ©ç”¨diffusion modelæ¥è·å–å›¾åƒä¹‹é—´çš„correspondenceï¼ŒåŒæ ·åœ°ï¼Œä¹Ÿæ˜¯é’ˆå¯¹semantic, geometric, å’Œ temporalæ•°æ®å…³è”,å¹¶ä¸”ä¸éœ€è¦ç”¨task-specifæ•°æ®æ¥è¿›è¡Œç›‘ç£æˆ–è€…fine tuningã€‚

diffusion modelä¸€èˆ¬æ˜¯ç”¨äºåšå›¾åƒç”Ÿæˆçš„ï¼Œé‚£ä¹ˆæœ€å…³é”®çš„observationå°±æ˜¯å®ƒåœ¨ image-to-image translationä»¥åŠimage editingä¸Šæœ‰å¥½çš„è¡¨ç°ï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ã€‚è€Œè¿™ä¸ªè¿‡ç¨‹å®é™…ä¸Šå°±æ˜¯éšå¼çš„å°†ä¸¤å¼ å›¾ç‰‡çš„æ•°æ®å…³è”å¯¹åº”èµ·æ¥ï¼Œå› æ­¤diffusion modelåº”è¯¥ä¹Ÿå¯ä»¥ç”¨äºåšå›¾åƒä¹‹é—´çš„æ•°æ®å…³è”

<div align="center">
  <img src="https://github.com/Tsingularity/dift/raw/main/assets/edit_cat.gif" width="80%" />
<figcaption>  
æ¨¡å‹å¾ˆå¥½çš„çŸ¥é“è¦ä¿®æ”¹çš„ä½ç½®åœ¨å“ªé‡Œï¼Œè€Œå…¶ä½™åŒºåŸŸä¸å˜ï¼Œè¿™éœ€è¦æœ‰å¾ˆå¼ºçš„å…³è”èƒ½åŠ› (must implicitly reason about correspondence between the two categories)
</figcaption>
</div>

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ‰€è°“çš„semantic correspondenceä¹Ÿå°±æ˜¯æŒ‡å®šäº†ä½ç½®(æ¯”å¦‚é¸­å­çš„ç†Šçš„è€³æœµ)ï¼Œé‚£ä¹ˆåœ¨å„ç§ä¸åŒä½†ç›¸ä¼¼çš„å›¾åƒä¸Šä¹Ÿå¯ä»¥æŠŠè€³æœµçš„ç‰¹å¾ç‚¹å…³è”å‡ºæ¥

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250321162635.png" width="60%" />
<figcaption>  
</figcaption>
</div>

Diffusion modelsæ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œå°†æ­£æ€åˆ†å¸ƒè½¬æ¢ä¸ºä»»æ„çš„æ•°æ®åˆ†å¸ƒçš„å½¢å¼ã€‚è€Œåœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œå¸¦æœ‰ä¸åŒå¹…åº¦çš„é«˜æ–¯å™ªå£°ä¼šè¢«åŠ åˆ°æ•°æ®ç‚¹ä¸Šï¼ˆclean data pointï¼‰ä»¥è·å–å¸¦å™ªå£°çš„data pointï¼Œå¦‚ä¸‹å…¬å¼æ‰€ç¤º

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250321163431.png" width="80%" />
<figcaption>  
</figcaption>
</div>

è€Œä¸€ä¸ªç¥ç»ç½‘ç»œ$f_{\theta}$åˆ™ä¼šç”¨äºå­¦ä¹ ä»¥å›¾åƒ$x_{t}$å’Œæ—¶é—´$t$ä¸ºè¾“å…¥ï¼Œé¢„æµ‹å™ªå£°$\varepsilon$.
åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸï¼Œç½‘ç»œ$f_{\theta}$ä¸€èˆ¬æ˜¯U-Netï¼Œè€Œç»è¿‡è®­ç»ƒåï¼Œ$f_{\theta}$å¯ä»¥ç”¨æ¥é€†è½¬diffusionçš„è¿‡ç¨‹ï¼ˆ"diffusion backward process"ï¼‰ï¼š
ä»ä¸€ä¸ªæ¥è‡ªäºæ­£æ€åˆ†å¸ƒé‡‡æ ·çš„çº¯å™ªå£°$x_{T}$ï¼Œ$f_{\theta}$å¯ä»¥è¿­ä»£ä¼°ç®—æ¥è‡ªäºå™ªå£°å›¾ç‰‡$x_{t}$çš„å™ªå£°$\varepsilon$ï¼Œç„¶åå»æ‰è¿™ä¸ªå™ªå£°æ¥è·å–æ›´æ¸…æ™°çš„æ•°æ®$x_{t-1}$ï¼Œæœ€ç»ˆè·å–ä¸€ä¸ªåŸæ•°æ®åˆ†å¸ƒä¸‹çš„$x_{0}$

é‚£ä¹ˆé’ˆå¯¹ä¸Šé¢å›¾åƒç”Ÿæˆçš„è¿‡ç¨‹ï¼Œé€šè¿‡æå–backward processä¸­ï¼Œç‰¹å¾æ—¶é—´$t$çš„ä¸­é—´å±‚çš„feature mapï¼Œç„¶åç”¨å…¶æ¥å»ºç«‹ä¸¤å¼ ä¸åŒç”Ÿæˆå›¾ç‰‡ä¹‹é—´çš„correspondenceï¼Œå¦‚ä¸‹å…¬å¼æ‰€ç¤º

<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250321164543.png" width="80%" />
<figcaption>  
</figcaption>
</div>

è€Œå¯¹äºåˆ°åº•åº”è¯¥æ‹¿å“ªä¸€ä¸ª$t$å¯¹åº”çš„ç½‘ç»œï¼Œä½œè€…å‘ç°è¶Šå¤§çš„$t$ä»¥åŠè¶Šå‰çš„ç½‘ç»œå±‚å°±æœ‰æ›´å¤šå¯è¯†åˆ«çš„è¯­ä¹‰ç‰¹å¾ï¼Œè€Œè¶Šå°çš„$t$ä»¥åŠè¶Šåçš„å±‚åˆ™ä¼šæ›´å¤šçš„low-levelç»†èŠ‚ã€‚ä½œè€…é€šè¿‡æ¶ˆèå®éªŒæ¥éªŒè¯äº†è¿™éƒ¨åˆ†ï¼ˆå…·ä½“è¯·è§åŸæ–‡ï¼‰

PSï¼šä¸ªäººæ„Ÿè§‰å°±æ˜¯ä½œè€…å‡è®¾Diffusion modelsæ˜¯å¯ä»¥è·å–ä¸¤å¼ å›¾åƒä¹‹é—´çš„å…³è”çš„ï¼Œç„¶åå°±ç¡®å®ä»Diffusion modelsä¸­çš„ä¸€å±‚è·å¾—çš„feature mapä½œä¸ºæè¿°å­ï¼Œè€Œè¿™åˆç¡®å®å¯ä»¥ç”¨ã€‚ç„¶åå†ä»ç†è®ºåæ¨çš„~~~

è¯­ä¹‰ä»¥åŠtemporal trackingå¯èƒ½ä¸æ˜¯SLAMä¸­å…³æ³¨çš„ï¼Œè¿™é‡Œçœ‹çœ‹å®ƒå‡ ä½•åŒ¹é…çš„æ•ˆæœ
<div align="center">
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250321165458.png" width="80%" />
  <img src="../images/å¾®ä¿¡æˆªå›¾_20250321165531.png" width="80%" />
<figcaption>
 after removing outliers with RANSAC  
</figcaption>
</div>

PSï¼šå¯¹äºdiffusion-based feature matchingçš„çœ‹æ³•ï¼š
æ„Ÿè§‰è¿™ä¸€ç³»åˆ—çš„diffusion-based matchingçš„è®ºæ–‡é¦–å…ˆéƒ½æ˜¯ä»¥è¯­ä¹‰åŒ¹é…ä¸ºä¸»çš„ï¼Œæ¯•ç«Ÿdiffusionæœ¬èº«å°±æ˜¯å›¾åƒç”Ÿæˆæˆ–è€…translationç­‰ç›¸å…³çš„ï¼Œå› æ­¤å¯ä»¥åšåˆ°è¯­ä¹‰è½¬æ¢åä»ç„¶å¯ä»¥å®ç°è¾ƒå¥½çš„åŒ¹é…ã€‚è€Œå¯¹äºgeometric å’Œ temporalçš„ç‰¹å¾åŒ¹é…å…¶å®å°±æ˜¯åœ¨è¯­ä¹‰çš„åŸºç¡€ä¸Šçš„é™ç»´æ‰“å‡»äº†hhhï¼Œæ¯•ç«Ÿè¯­ä¹‰éƒ½èƒ½åŒ¹é…ä¸Šï¼Œæ›´ä½•å†µåªæ˜¯å‡ ä½•çš„è§’åº¦ä¸ä¸€æ ·å‘¢ã€‚