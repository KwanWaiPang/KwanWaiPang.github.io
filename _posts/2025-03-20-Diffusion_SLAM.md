---
layout: post
title: "Paper Surveyä¹‹â€”â€”Awesome Diffusion-based SLAM"
date:   2025-03-20
tags: [SLAM, Deep Learning]
comments: true
author: kwanwaipang
toc: false #true
---


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# å¼•è¨€
ä¹‹å‰åšå®¢åœ¨å¯¹Transformer-based SLAMè¿›è¡Œè°ƒç ”çš„æ—¶å€™ï¼Œæ— æ„ä¸­å‘ç°ç«Ÿç„¶è¿˜è¦åŸºäºDiffusionçš„SLAMç›¸å…³çš„å·¥ä½œï¼Œä¸ºæ­¤é’ˆå¯¹å…¶è¿›è¡Œè°ƒç ”ï¼Œçœ‹çœ‹Diffusionåœ¨SLAMã€å…‰æµã€æ·±åº¦ä¼°è®¡ã€æ•°æ®å…³è”ã€å§¿æ€ä¼°è®¡ç­‰ç›¸å…³ä»»åŠ¡ä¸Šè¡¨ç°å¦‚ä½•~

æœ¬åšæ–‡ä»…ä¾›æœ¬äººå­¦ä¹ è®°å½•ç”¨~

* ç›®å½•
{:toc}


# Paper List

* æ³¨æ„ï¼Œæ­¤å¤„éæœ€æ–°ç‰ˆï¼Œä»…ä»…æ˜¯å†™æ­¤åšå®¢çš„æ—¶å€™çš„è®°å½•
* Keep update the paper list in: [Awesome-Diffusion-based-SLAM](https://github.com/KwanWaiPang/Awesome-Diffusion-based-SLAM)

<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->

## Matching

or data association, or correspondence

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[MATCHA: Towards Matching Anything](https://arxiv.org/pdf/2501.14945)|---|SD+DINOv2|
|2024|`CVPR`|[Sd4match: Learning to prompt stable diffusion model for semantic matching](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_SD4Match_Learning_to_Prompt_Stable_Diffusion_Model_for_Semantic_Matching_CVPR_2024_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/ActiveVisionLab/SD4Match.svg)](https://github.com/ActiveVisionLab/SD4Match)|[website](https://sd4match.active.vision/)|
|2023|`NIPS`|[Emergent correspondence from image diffusion](https://proceedings.neurips.cc/paper_files/paper/2023/file/0503f5dce343a1d06d16ba103dd52db1-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/Tsingularity/dift.svg)](https://github.com/Tsingularity/dift)|[website](https://diffusionfeatures.github.io/)<br>DIFT|
|2023|`NIPS`|[A tale of two features: Stable diffusion complements dino for zero-shot semantic correspondence](https://proceedings.neurips.cc/paper_files/paper/2023/file/8e9bdc23f169a05ea9b72ccef4574551-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/Junyi42/sd-dino.svg)](https://github.com/Junyi42/sd-dino)|[website](https://sd-complements-dino.github.io/)<br>SD+DINO|
|2023|`NIPS`|[Diffusion hyperfeatures: Searching through time and space for semantic correspondence](https://proceedings.neurips.cc/paper_files/paper/2023/file/942032b61720a3fd64897efe46237c81-Paper-Conference.pdf)|[![Github stars](https://img.shields.io/github/stars/diffusion-hyperfeatures/diffusion_hyperfeatures.svg)](https://github.com/diffusion-hyperfeatures/diffusion_hyperfeatures)|[website](https://diffusion-hyperfeatures.github.io/)<br>DHF|


## Depth Estimation

or 3D reconstruction

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2025|`arXiv`|[Bolt3D: Generating 3D Scenes in Seconds](https://arxiv.org/pdf/2503.14445)|---|[website](https://szymanowiczs.github.io/bolt3d)|
|2025|`arXiv`|[Stable Virtual Camera: Generative View Synthesis with Diffusion Models](https://arxiv.org/pdf/2503.14489)|[![Github stars](https://img.shields.io/github/stars/Stability-AI/stable-virtual-camera.svg)](https://github.com/Stability-AI/stable-virtual-camera) |---|
|2025|`CVPR`|[Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models](https://arxiv.org/pdf/2503.01774?)|---|[website](https://research.nvidia.com/labs/toronto-ai/difix3d/)|
|2025|`CVPR`|[Multi-view Reconstruction via SfM-guided Monocular Depth Estimation](https://arxiv.org/pdf/2503.14483)|[![Github stars](https://img.shields.io/github/stars/zju3dv/Murre.svg)](https://github.com/zju3dv/Murre)|[website](https://zju3dv.github.io/murre/)|
|2025|`CVPR`|[Align3r: Aligned monocular depth estimation for dynamic videos](https://arxiv.org/pdf/2412.03079)|[![Github stars](https://img.shields.io/github/stars/jiah-cloud/Align3R.svg)](https://github.com/jiah-cloud/Align3R)|---|
|2024|`NIPS`|[Cat3d: Create anything in 3d with multi-view diffusion models](https://arxiv.org/pdf/2405.10314)|---|[website](https://cat3d.github.io/)|
|2024|`ECCV`|[Diffusiondepth: Diffusion denoising approach for monocular depth estimation](https://arxiv.org/pdf/2303.05021)|[![Github stars](https://img.shields.io/github/stars/duanyiqun/DiffusionDepth.svg)](https://github.com/duanyiqun/DiffusionDepth)|[website](https://igl-hkust.github.io/Align3R.github.io/)|
|2023|`NIPS`|[The surprising effectiveness of diffusion models for optical flow and monocular depth estimation](https://proceedings.neurips.cc/paper_files/paper/2023/file/7c119415672ae2186e17d492e1d5da2f-Paper-Conference.pdf)|---|[website](https://diffusion-vision.github.io/)|
|2023|`arXiv`|[Monocular depth estimation using diffusion models](https://arxiv.org/pdf/2302.14816)|---|[website](https://depth-gen.github.io/)| 
|2023|`arXiv`|[Mvdream: Multi-view diffusion for 3d generation](https://arxiv.org/pdf/2308.16512)|[![Github stars](https://img.shields.io/github/stars/bytedance/MVDream.svg)](https://github.com/bytedance/MVDream)|[website](https://mv-dream.github.io/)|

## Pose Estimation

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2023|`ICCV`|[Posediffusion: Solving pose estimation via diffusion-aided bundle adjustment](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_PoseDiffusion_Solving_Pose_Estimation_via_Diffusion-aided_Bundle_Adjustment_ICCV_2023_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/facebookresearch/PoseDiffusion.svg)](https://github.com/facebookresearch/PoseDiffusion)|[website](https://posediffusion.github.io/)|


## Other Resource

* [What is Diffusion?](https://kwanwaipang.github.io/Diffusion/)
* Survey for Learning-based VO,VIO,IOï¼š[Paper List](https://github.com/KwanWaiPang/Awesome-Learning-based-VO-VIO) and [Blog](https://kwanwaipang.github.io/Learning-based-VO-VIO/)
* Survey for Transformer-based SLAMï¼š[Paper List](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM) and [Blog](https://kwanwaipang.github.io/Transformer_SLAM/)
* Survey for NeRF-based SLAMï¼š[Blog](https://kwanwaipang.github.io/Awesome-NeRF-SLAM/)
* Survey for 3DGS-based SLAM: [Blog](https://kwanwaipang.github.io/File/Blogs/Poster/survey_3DGS_SLAM.html)
* [Awesome-Diffusion-Models](https://github.com/diff-usion/Awesome-Diffusion-Models)
* Some basic paper for Diffusion Model:

<!-- |---|`arXiv`|---|---|---| -->
<!-- [![Github stars](https://img.shields.io/github/stars/***.svg)]() -->

| Year | Venue | Paper Title | Repository | Note |
|:----:|:-----:| ----------- |:----------:|:----:|
|2022|`CVPR`|[High-resolution image synthesis with latent diffusion models](https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf)|[![Github stars](https://img.shields.io/github/stars/CompVis/latent-diffusion.svg)](https://github.com/CompVis/latent-diffusion)|stable diffusion|
|2021|`NIPS`|[Diffusion models beat gans on image synthesis](https://proceedings.neurips.cc/paper_files/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf)|---|Ablated Diffusion Model(ADM)|
|2020|`ICLR`|[Denoising diffusion implicit models](https://arxiv.org/pdf/2010.02502)|---|DDIM|
|2020|`NIPS`|[Denoising diffusion probabilistic models](https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf)|[![Github stars](https://img.shields.io/github/stars/hojonathanho/diffusion.svg)](https://github.com/hojonathanho/diffusion)|DDPM|





<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->

# Paper Reading
æ¥ä¸‹æ¥é‡ç‚¹é˜…è¯»å‡ ç¯‡è®ºæ–‡

## MATCHA: Towards Matching Anything

å»ºç«‹äºinsights:`diffusion model features can encode multiple correspondence types`,ä½œè€…æå‡ºåŸºäºdiffusion model çš„MATCHAï¼Œå¹¶è¿›ä¸€æ­¥é€šè¿‡åŸºäºæ³¨æ„åŠ›çš„åŠ¨æ€èåˆé«˜çº§è¯­ä¹‰å’Œä½çº§å‡ ä½•ç‰¹å¾ï¼Œè¿›è€Œè·å–å…·æœ‰ä»£è¡¨æ€§çš„ã€é€šç”¨çš„ä»¥åŠå¼ºé²æ£’æ€§çš„ç‰¹å¾ã€‚

è¿™é‡Œæ‰€è°“çš„ç‰¹å¾åŒ¹é…åŒ…æ‹¬äº†å‡ ä½•( geometric)ã€è¯­ä¹‰(semantic)ã€æ—¶é—´ï¼ˆtemporalï¼‰ç­‰å¤šä¸ªç»´åº¦çš„ç‰¹å¾åŒ¹é…ï¼Œä¹Ÿå°±æ˜¯åŒä¸€ä¸ªæ¡†æ¶,åªéœ€è¦å­¦ä¹ å•ä¸ªç‰¹å¾çš„æè¿°å­å³å¯å®Œæˆè¿™ä¸‰ä¸ªä»»åŠ¡ä¸‹çš„ç‰¹å¾åŒ¹é…
<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250320151734.png" width="60%" />
<figcaption>  
</figcaption>
</div>

MATCHAæ•´åˆäº†æ¥è‡ªäºDINO V2(ã€Š[Dinov2: Learning robust visual features without supervision](https://arxiv.org/pdf/2304.07193)ã€‹)çš„ç‰¹å¾æ¥è¿›ä¸€æ­¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
å…³äºè¿™ç‚¹ï¼Œåº”è¯¥æ˜¯ç”±äºç¼ºä¹æ¥è‡ªè¯­ä¹‰ä»¥åŠå‡ ä½•çš„è¶³å¤Ÿçš„çœŸå®æ•°æ®ï¼Œå› æ­¤ä½œè€…ç›´æ¥ç”¨äº†é¢„è®­ç»ƒçš„transformeræ¨¡å‹æ¥å¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚å¦‚ä¸‹å›¾æ‰€ç¤º

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250320153747.png" width="60%" />
<figcaption>  
</figcaption>
</div>
DINO V2æä¾›çš„åº”è¯¥æ˜¯ semantic knowledge, DIFTæä¾›çš„semanticå’Œgeometricä¿¡æ¯ï¼Œåœ¨å›¾ä¾‹ä¸Šå…·æœ‰äº’è¡¥æ€§ï¼Œè€ŒMATCHAåˆ™æ˜¯åˆ©ç”¨äº†è¿™ä¸‰ç§åŸºæœ¬çš„ç‰¹å¾æ¥æä¾›æ›´å¯é çš„ç‰¹å¾åŒ¹é…ã€‚

å…¶æ¡†æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚é¦–å…ˆé€šè¿‡stable diffusionæ¥åˆ†åˆ«æå–è¯­ä¹‰ä»¥åŠå‡ ä½•ç‰¹å¾ï¼Œå¹¶é€šè¿‡transformeræ¥èåˆä¸€èµ·ï¼Œå†é€šè¿‡å¯¹åº”çš„çœŸå€¼æ¥åˆ†åˆ«è®­ç»ƒã€‚
ç„¶åæŠŠæ¥è‡ªäºDINOv2çš„ç‰¹å¾ä¸stable diffusionçš„è¯­ä¹‰åŠå‡ ä½•ç‰¹å¾concatenateåˆ°ä¸€èµ·ï¼Œä½œä¸ºmatching anythingçš„ç‰¹å¾.
è¯´å®è¯ï¼Œè¿™ä¸ªæ¡†æ¶æ„Ÿè§‰æœ‰ç‚¹å¤§åŠ›å‡ºå¥‡è¿¹çš„æ„å‘³ï¼Œstable diffusion+transformer+DINOv2å…¨éƒ¨æŸ”åˆ°ä¸€å—,è€Œå…¶ä¸­çš„`stable diffusion+transformer`åˆ™æ˜¯DIFTï¼Œå› æ­¤ç®—æ˜¯DIFT+DINOv2

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250320154105.png" width="60%" />
<figcaption>  
</figcaption>
</div>

ä¸‹é¢çœ‹çœ‹å®éªŒæ•ˆæœ

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250320162153.png" width="80%" />
<figcaption>  
</figcaption>
</div>
çº¢è‰²åº”è¯¥æ˜¯è¯¯åŒ¹é…çš„ï¼Œä½†æ˜¯å“ªæ€•æ˜¯å…­å¼ å›¾ï¼Œæ„Ÿè§‰ä¸Šä¹Ÿå°±åªæœ‰ä¸¤å¼ MATCHAæ²¡æœ‰è¯¯åŒ¹é…ï¼Œå…¶ä»–å¯¹æ¯”æ•ˆæœä¸ªäººè§‰å¾—ä¸å¤ªæ˜æ˜¾ã€‚æ¯•ç«Ÿè€ƒè™‘åˆ°æ˜¯æŠŠå‰ä¸¤è€…èåˆåˆ°ä¸€èµ·çš„å¤§æ¨¡å‹ğŸ˜‚

å½“ç„¶ï¼Œä½œè€…ä¹Ÿæœ‰è·ŸMASt3Rç­‰SOTAå¯¹æ¯”çš„å‡ ä½•ã€è¯­ä¹‰ã€è·Ÿè¸ªç­‰åŒ¹é…çš„æ•ˆæœï¼ˆå¤ªå¤šäº†ï¼Œå°±éšæœºåˆ—å‡ºä¸€äº›ï¼Œæ›´å¤šçš„è¯·è§åŸæ–‡~ï¼‰ã€‚
ä¸‹å›¾çš„ç»“æœéƒ½æ˜¯RANSACè¾“å‡ºçš„inliers
<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250320162627.png" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250320162710.png" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

è¯­ä¹‰åŒ¹é…çš„æ•ˆæœ

<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250320162840.png" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250320162852.png" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>


## Emergent correspondence from image diffusion

è¿™ç¯‡è®ºæ–‡å°±æ˜¯DIFT(DIffusion FeaTures)ï¼Œä¹Ÿå°±æ˜¯åˆ©ç”¨diffusion modelæ¥è·å–å›¾åƒä¹‹é—´çš„correspondenceï¼ŒåŒæ ·åœ°ï¼Œä¹Ÿæ˜¯é’ˆå¯¹semantic, geometric, å’Œ temporalæ•°æ®å…³è”,å¹¶ä¸”ä¸éœ€è¦ç”¨task-specifæ•°æ®æ¥è¿›è¡Œç›‘ç£æˆ–è€…fine tuningã€‚

diffusion modelä¸€èˆ¬æ˜¯ç”¨äºåšå›¾åƒç”Ÿæˆçš„ï¼Œé‚£ä¹ˆæœ€å…³é”®çš„observationå°±æ˜¯å®ƒåœ¨ image-to-image translationä»¥åŠimage editingä¸Šæœ‰å¥½çš„è¡¨ç°ï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰ã€‚è€Œè¿™ä¸ªè¿‡ç¨‹å®é™…ä¸Šå°±æ˜¯éšå¼çš„å°†ä¸¤å¼ å›¾ç‰‡çš„æ•°æ®å…³è”å¯¹åº”èµ·æ¥ï¼Œå› æ­¤diffusion modelåº”è¯¥ä¹Ÿå¯ä»¥ç”¨äºåšå›¾åƒä¹‹é—´çš„æ•°æ®å…³è”

<div align="center">
  <img src="https://github.com/Tsingularity/dift/raw/main/assets/edit_cat.gif" width="80%" />
<figcaption>  
æ¨¡å‹å¾ˆå¥½çš„çŸ¥é“è¦ä¿®æ”¹çš„ä½ç½®åœ¨å“ªé‡Œï¼Œè€Œå…¶ä½™åŒºåŸŸä¸å˜ï¼Œè¿™éœ€è¦æœ‰å¾ˆå¼ºçš„å…³è”èƒ½åŠ› (must implicitly reason about correspondence between the two categories)
</figcaption>
</div>

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ‰€è°“çš„semantic correspondenceä¹Ÿå°±æ˜¯æŒ‡å®šäº†ä½ç½®(æ¯”å¦‚é¸­å­çš„ç†Šçš„è€³æœµ)ï¼Œé‚£ä¹ˆåœ¨å„ç§ä¸åŒä½†ç›¸ä¼¼çš„å›¾åƒä¸Šä¹Ÿå¯ä»¥æŠŠè€³æœµçš„ç‰¹å¾ç‚¹å…³è”å‡ºæ¥

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250321162635.png" width="60%" />
<figcaption>  
</figcaption>
</div>

Diffusion modelsæ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œå°†æ­£æ€åˆ†å¸ƒè½¬æ¢ä¸ºä»»æ„çš„æ•°æ®åˆ†å¸ƒçš„å½¢å¼ã€‚è€Œåœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œå¸¦æœ‰ä¸åŒå¹…åº¦çš„é«˜æ–¯å™ªå£°ä¼šè¢«åŠ åˆ°æ•°æ®ç‚¹ä¸Šï¼ˆclean data pointï¼‰ä»¥è·å–å¸¦å™ªå£°çš„data pointï¼Œå¦‚ä¸‹å…¬å¼æ‰€ç¤º

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250321163431.png" width="80%" />
<figcaption>  
</figcaption>
</div>

è€Œä¸€ä¸ªç¥ç»ç½‘ç»œ$f_{\theta}$åˆ™ä¼šç”¨äºå­¦ä¹ ä»¥å›¾åƒ$x_{t}$å’Œæ—¶é—´$t$ä¸ºè¾“å…¥ï¼Œé¢„æµ‹å™ªå£°$\varepsilon$.
åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸï¼Œç½‘ç»œ$f_{\theta}$ä¸€èˆ¬æ˜¯U-Netï¼Œè€Œç»è¿‡è®­ç»ƒåï¼Œ$f_{\theta}$å¯ä»¥ç”¨æ¥é€†è½¬diffusionçš„è¿‡ç¨‹ï¼ˆ"diffusion backward process"ï¼‰ï¼š
ä»ä¸€ä¸ªæ¥è‡ªäºæ­£æ€åˆ†å¸ƒé‡‡æ ·çš„çº¯å™ªå£°$x_{T}$ï¼Œ$f_{\theta}$å¯ä»¥è¿­ä»£ä¼°ç®—æ¥è‡ªäºå™ªå£°å›¾ç‰‡$x_{t}$çš„å™ªå£°$\varepsilon$ï¼Œç„¶åå»æ‰è¿™ä¸ªå™ªå£°æ¥è·å–æ›´æ¸…æ™°çš„æ•°æ®$x_{t-1}$ï¼Œæœ€ç»ˆè·å–ä¸€ä¸ªåŸæ•°æ®åˆ†å¸ƒä¸‹çš„$x_{0}$

é‚£ä¹ˆé’ˆå¯¹ä¸Šé¢å›¾åƒç”Ÿæˆçš„è¿‡ç¨‹ï¼Œé€šè¿‡æå–backward processä¸­ï¼Œç‰¹å¾æ—¶é—´$t$çš„ä¸­é—´å±‚çš„feature mapï¼Œç„¶åç”¨å…¶æ¥å»ºç«‹ä¸¤å¼ ä¸åŒç”Ÿæˆå›¾ç‰‡ä¹‹é—´çš„correspondenceï¼Œå¦‚ä¸‹å…¬å¼æ‰€ç¤º

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250321164543.png" width="80%" />
<figcaption>  
</figcaption>
</div>

è€Œå¯¹äºåˆ°åº•åº”è¯¥æ‹¿å“ªä¸€ä¸ª$t$å¯¹åº”çš„ç½‘ç»œï¼Œä½œè€…å‘ç°è¶Šå¤§çš„$t$ä»¥åŠè¶Šå‰çš„ç½‘ç»œå±‚å°±æœ‰æ›´å¤šå¯è¯†åˆ«çš„è¯­ä¹‰ç‰¹å¾ï¼Œè€Œè¶Šå°çš„$t$ä»¥åŠè¶Šåçš„å±‚åˆ™ä¼šæ›´å¤šçš„low-levelç»†èŠ‚ã€‚ä½œè€…é€šè¿‡æ¶ˆèå®éªŒæ¥éªŒè¯äº†è¿™éƒ¨åˆ†ï¼ˆå…·ä½“è¯·è§åŸæ–‡ï¼‰

PSï¼šä¸ªäººæ„Ÿè§‰å°±æ˜¯ä½œè€…å‡è®¾Diffusion modelsæ˜¯å¯ä»¥è·å–ä¸¤å¼ å›¾åƒä¹‹é—´çš„å…³è”çš„ï¼Œç„¶åå°±ç¡®å®ä»Diffusion modelsä¸­çš„ä¸€å±‚è·å¾—çš„feature mapä½œä¸ºæè¿°å­ï¼Œè€Œè¿™åˆç¡®å®å¯ä»¥ç”¨ã€‚ç„¶åå†ä»ç†è®ºåæ¨çš„~~~

è¯­ä¹‰ä»¥åŠtemporal trackingå¯èƒ½ä¸æ˜¯SLAMä¸­å…³æ³¨çš„ï¼Œè¿™é‡Œçœ‹çœ‹å®ƒå‡ ä½•åŒ¹é…çš„æ•ˆæœ
<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250321165458.png" width="80%" />
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250321165531.png" width="80%" />
<figcaption>
 after removing outliers with RANSAC  
</figcaption>
</div>

PSï¼šå¯¹äºdiffusion-based feature matchingçš„çœ‹æ³•ï¼š
æ„Ÿè§‰è¿™ä¸€ç³»åˆ—çš„diffusion-based matchingçš„è®ºæ–‡é¦–å…ˆéƒ½æ˜¯ä»¥è¯­ä¹‰åŒ¹é…ä¸ºä¸»çš„ï¼Œæ¯•ç«Ÿdiffusionæœ¬èº«å°±æ˜¯å›¾åƒç”Ÿæˆæˆ–è€…translationç­‰ç›¸å…³çš„ï¼Œå› æ­¤å¯ä»¥åšåˆ°è¯­ä¹‰è½¬æ¢åä»ç„¶å¯ä»¥å®ç°è¾ƒå¥½çš„åŒ¹é…ã€‚è€Œå¯¹äºgeometric å’Œ temporalçš„ç‰¹å¾åŒ¹é…å…¶å®å°±æ˜¯åœ¨è¯­ä¹‰çš„åŸºç¡€ä¸Šçš„é™ç»´æ‰“å‡»äº†hhhï¼Œæ¯•ç«Ÿè¯­ä¹‰éƒ½èƒ½åŒ¹é…ä¸Šï¼Œæ›´ä½•å†µåªæ˜¯å‡ ä½•çš„è§’åº¦ä¸ä¸€æ ·å‘¢ã€‚

## STABLE VIRTUAL CAMERA: Generative View Synthesis with Diffusion Models
STABLE VIRTUAL CAMERA (SEVA)ï¼Œå°±æ˜¯è¾“å…¥è§†è§’ä»¥åŠç›¸æœºposeç­‰ä¿¡æ¯ï¼Œå¯ä»¥è·å¾—åœºæ™¯çš„æ–°è§†è§‰ã€‚ä½†æ˜¯è·Ÿå…¶ä»–æ–°è§†è§‰åˆæˆçš„å·¥ä½œä¸ä¸€æ ·ï¼Œä¸ä¾èµ–äºå›ºå®šçš„è¾“å…¥ï¼Œæ¯”å¦‚åƒNeRFä¹‹ç±»çš„ï¼Œéœ€è¦360åº¦å…¨æ–¹ä½è¦†ç›–ï¼Œè§†è§’é—´çš„ä½ç§»ä¸èƒ½å¤ªå¤§ã€‚å…·ä½“è§nerfç³»åˆ—çš„å·¥ä½œå°±çŸ¥é“ğŸ˜‚ï¼Œç›¸é‚»ä¸¤ä¸ªè§†è§’åŸºæœ¬ä¸Šæ˜¯è‚‰çœ¼åˆ†ä¸å‡ºåŒºåˆ«çš„å°ä½ç§»ï¼Œä¸ç„¶æ•ˆæœå°±éå¸¸å·®ã€‚è€Œè¿™ç¯‡å·¥ä½œåº”è¯¥å°±æ˜¯åˆ©ç”¨äº†Diffusion Modelså¯ä»¥å¼¥è¡¥è¿™äº›ç¼ºé™·ä¸ºmotivationçš„ï¼š
1. å¯ä»¥handleå¤§è§†ç‚¹å˜åŒ–å»ºæ¨¡ä¸æ—¶é—´å¹³æ»‘
2. åº”å¯¹ä»»æ„é•¿åº¦çš„ç›¸æœºè½¨è¿¹ï¼ˆä¹Ÿå°±æ˜¯ä»»æ„è¾“å…¥è§†è§’ï¼‰
3. åœ¨æ–°è§†è§‰åˆæˆä»»åŠ¡ä¸Šï¼Œå…·æœ‰æ³›åŒ–èƒ½åŠ›

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250322131401.png" width="80%" />
<figcaption>  
</figcaption>
</div>

SEVAè§£å†³çš„æ˜¯æ–°è§†è§‰åˆæˆï¼ˆNovel view synthesisï¼ŒNVSï¼‰çš„é—®é¢˜ã€‚å…¶ç»“æ„å¦‚ä¸‹ï¼Œé‡‡ç”¨çš„æ˜¯Stable Diffusionçš„ç»“æ„ï¼Œå¹¶ä¸”ç»“åˆäº†self-attention

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250322132519.png" width="80%" />
<figcaption>  
</figcaption>
</div>

## Bolt3D: Generating 3D Scenes in Seconds
è¿™ç¯‡è®ºæ–‡åˆ™æ˜¯å±äºä¸‰ç»´é‡å»ºé¢†åŸŸçš„ï¼Œ ç”¨å•ä¸ªGPUï¼Œåœ¨7ç§’å†…è·å–3ç»´åœºæ™¯ã€‚
é‡‡ç”¨çš„æ˜¯2D diffusion networkæ¥é¢„æµ‹å‡ºä¸€è‡´æ€§å¼ºçš„3Dåœºæ™¯
è€Œä¸ºäº†è®­ç»ƒè¿™ä¸ªæ¨¡å‹ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªå¤§å°ºåº¦çš„3Dæ•°æ®é›†ã€‚

å½“å‰çš„diffusion modelåœ¨å›¾åƒä»¥åŠè§†é¢‘çš„ç”Ÿæˆéƒ½æœ‰ä¸å°‘çš„å·¥ä½œï¼Œä½†æ˜¯éƒ½æ˜¯åŸºäº2Då›¾åƒçš„ï¼Œå¹¶ä¸æ˜¯3Då›¾åƒçš„ï¼ˆæ¯”å¦‚ä¸Šä¸€ç¯‡ï¼Œåªæ˜¯æ–°è§†è§‰åˆæˆï¼Œé‚£ä¹ˆä¹Ÿåªæ˜¯2Då›¾åƒå±‚é¢çš„ï¼‰ã€‚
è€Œä¹‹æ‰€ä»¥ç”¨diffusion modelç”Ÿæˆ3Dè¿™ä¹ˆå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä¸»è¦æ˜¯ç”±äºä»¥ä¸‹ä¸¤ä¸ªåŸå› ï¼š
1. è¡¨ç¤ºå’Œæ„é€ 3Dæ•°æ®ä»¥èƒ½å¤Ÿè®­ç»ƒä»¥é«˜åˆ†è¾¨ç‡ç”Ÿæˆå®Œæ•´åœºæ™¯çš„æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ä¸ªæœªè§£å†³çš„é—®é¢˜ã€‚ï¼ˆä¹Ÿå°±æ˜¯æ•°æ®é›†çš„é—®é¢˜ï¼‰
2. çœŸå€¼3Dåœºæ™¯ä¹Ÿæ˜¯ç¨€ç¼ºçš„ï¼ˆæ¯”èµ·ç”Ÿæˆæ¨¡å‹çš„2Dæ•°æ®é›†ï¼‰ï¼Œé‚£ä¹ˆä¹Ÿå°±æ˜¯æ•°æ®é›†çš„é—®é¢˜ã€‚

è€Œè¿™ä¹Ÿå¯¼è‡´å¤§å¤šæ•°çš„3Dç”Ÿæˆæ¨¡å‹åªèƒ½å±€é™äºåˆæˆç‰©ä½“ã€æ–°è§†è§‰ã€éƒ¨åˆ†â€œforward-facingâ€çš„åœºæ™¯ã€‚è€Œè¦çœŸæ­£åˆæˆ3Dåœºæ™¯ï¼Œéœ€è¦è¿›ä¸€æ­¥çš„é€šè¿‡NeRFæˆ–è€…3DGSï¼Œè™½ç„¶è¿™å¯ä»¥äº§ç”Ÿé«˜è´¨é‡çš„3Dæ•°æ®ï¼Œä½†æ˜¯ä¸ç°å®ã€‚

é‚£ä¹ˆå…¶å®è¯»åˆ°è¿™é‡Œï¼Œå°±å¾ˆæ˜¾ç„¶çš„ï¼Œæœ¬æ–‡å°±æ˜¯é€šè¿‡æ„å»ºäº†ä¸€ä¸ªå¥½çš„ã€å¤§çš„3Dæ•°æ®é›†å¯ä»¥å–‚ç»™existing 2D diffusion networkï¼Œä»¥åŠå¯ä»¥`leveraging powerful and scalable existing 2D diffusion network`ã€‚è€Œåœ¨è¿™ç¯‡è®ºæ–‡ä¹‹å‰çš„diffusion-based çš„3Dé‡å»ºçš„å·¥ä½œåŸºæœ¬éƒ½æ˜¯æœ‰å±€é™çš„â€œä¼ª3Dâ€
ä¸è¿‡å³ä½¿ä½œè€…å‰é¢è¿™æ ·è¯´ï¼Œä½†æ˜¯æœ¬æ–‡å®é™…ä¸Šåˆè¿˜æ˜¯å°†3Dåœºæ™¯è¡¨è¾¾ä¸ºä¸€ç³»åˆ—çš„å­˜åœ¨å¤šä¸ª2Dç½‘æ ¼ä¸‹çš„3D Gaussiansï¼Œå…¶ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤º

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250322140355.png" width="80%" />
<figcaption>  
</figcaption>
</div>

ç”Ÿæˆçš„è¿‡ç¨‹ä¸»è¦åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š
1. "denoising" æ¯ä¸ªé«˜æ–¯çš„color ä»¥åŠposition
2. å›å½’æ¯ä¸ªé«˜æ–¯çš„é€æ˜åº¦ï¼ˆopacityï¼‰ä»¥åŠå½¢çŠ¶ï¼ˆåº”è¯¥å°±æ˜¯æ—‹è½¬å’Œå°ºåº¦ç­‰é«˜æ–¯çƒçš„å±æ€§äº†~ï¼‰

è¾“å…¥ä¸€ç³»åˆ—çš„imageä»¥åŠå¯¹åº”çš„poseï¼Œæ¨¡å‹å¯ä»¥é¢„æµ‹åœºæ™¯çš„å¤–è§‚ï¼ˆpixel colorï¼‰ä»¥åŠåœºæ™¯ç‚¹çš„3Dåæ ‡ï¼Œç„¶åé€šè¿‡è®­ç»ƒä¸€ä¸ª Geometry Variational Auto-Encoderï¼ˆVAEï¼‰æ¥è·å–é«˜ç²¾åº¦çš„æ¯ä¸ªpixelçš„3Då‡ ä½•ä¿¡æ¯ã€‚
è€Œæ‰€æ„å»ºçš„æ•°æ®é›†å®é™…ä¸Šæ˜¯é€šè¿‡MAST3Rç”Ÿæˆçš„ï¼Œç„¶åç”¨è¿™ä¸ªæ•°æ®é›†æ¥è®­ç»ƒdiffusionä»¥åŠVAE

PSï¼šé‚£ä¹ˆä¹Ÿå°±æ˜¯ç”¨äº†Diffusion+VAE+3DGSæœ€ç»ˆæ‹Ÿåˆå‡ºç±»ä¼¼MAST3Rçš„æ•ˆæœï¼Ÿå¦‚æœæ˜¯è¿™æ ·çš„è¯ï¼Œé‚£ä¹ˆè‡³å°‘æ„Ÿè§‰diffusionåœ¨3D reconstructionè¿™ä¸ªä»»åŠ¡ä¸Šæ˜¯è¿œä¸å¦‚Transformerçš„ï¼Œè‡³å°‘æœ¬æ–‡å’Œä¸Šä¸€ç¯‡è®ºæ–‡è¯»ä¸‹æ¥è¿è§£æä¸ºä»€ä¹ˆç”¨diffusionéƒ½æ²¡æœ‰ã€‚è€ŒTransformeråˆ™æ˜¯ä»æ¦‚å¿µå±‚é¢ä¸Šå¾ˆå¥½çš„è¿›è¡Œäº†æ—¶ç©ºä¹‹é—´çš„å…³è”ï¼Œè€Œdiffusionä¼¼ä¹æ›´åŠ é€‚ç”¨äºç”Ÿæˆæ–¹é¢çš„ä»»åŠ¡ã€‚è€Œä»è®ºæ–‡ç½‘é¡µçš„ä¸€äº›demoæ•ˆæœæ¥çœ‹ï¼Œæ„Ÿè§‰ç”Ÿæˆçš„3Dæ¨¡å‹æ¯”è¾ƒä¸€èˆ¬~~~


## Posediffusion: Solving pose estimation via diffusion-aided bundle adjustment
è¿™ç¯‡è®ºæ–‡æå‡ºçš„å°±æ˜¯å°†sfmé—®é¢˜ç”¨probabilistic diffusion frameworkæ¥æ„å»ºã€‚å…¶å®åŸºäºä»¥ä¸‹çš„motivationçš„ï¼š
1. diffusion frameworkç›¸å½“äºbundle adjustmentçš„è¿­ä»£å¤„ç†çš„è¿‡ç¨‹ï¼ˆdiffusion frameworkè¿­ä»£åŠ å™ªæˆ–è€…å»å™ªå¯ä»¥ç­‰åŒäºè¿­ä»£çš„BAï¼‰
2. å°†diffusion framework formulateæˆBAçš„è¿‡ç¨‹å¯ä»¥å¾ˆå¥½çš„ä»å¯¹æå‡ ä½•ä¸­å¼•å…¥å‡ ä½•çº¦æŸ
3. åœ¨ç¨€ç–è§†è§’ä¸‹æœ‰å¥½çš„è¡¨ç°ï¼ˆåº”è¯¥å°±æ˜¯åˆ©ç”¨äº†diffusionç”Ÿæˆã€æ¨ç†çš„èƒ½åŠ›ï¼‰
4. å¯¹äºä»»æ„æ•°ç›®çš„å›¾åƒå¯ä»¥é¢„æµ‹å…¶å†…å‚å’Œå¤–å‚ã€‚

å…¶æ¡†æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚æ„Ÿè§‰è·ŸDDPMæ¨¡å‹å¾ˆåƒï¼Œåªæ˜¯æŠŠä¼°ç®—å™ªå£°æ”¹ä¸ºäº†ä¼°ç®—ç›¸æœºçš„å†…å¤–å‚ã€‚

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250322160058.png" width="80%" />
<figcaption>  
</figcaption>
</div>

å…¶ä¸­å»ºæ¨¡çš„$P(x|I)$å¯ä»¥ç†è§£ä¸ºå¯¹äºå›¾ç‰‡$I$å…¶ç›¸æœºçš„å‚æ•°$x$çš„æ¦‚ç‡åˆ†å¸ƒã€‚è€Œä»å›¾ç‰‡ä¼°ç®—ç›¸æœºå‚æ•°çš„æ¨¡å‹åˆ™æ˜¯ç”¨Transformeræ¥è®­ç»ƒçš„

<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250322160751.png" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250322160943.png" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

PSï¼šæœ¬è´¨ä¸Šå°±æ˜¯Transformerç›´æ¥å¯ä»¥è§£å†³çš„é—®é¢˜ï¼Œè¦æ”¹åˆ°diffusionè¿­ä»£å¤„ç†ï¼Œç”¨ç±»ä¼¼é€æ­¥åŠ é«˜æ–¯å»å™ªçš„è¿‡ç¨‹æ¥æ±‚pose

è‡³äºå®éªŒå…³äºå®šä½ç²¾åº¦æ–¹é¢çš„éªŒè¯åŸºæœ¬æ˜¯è·Ÿsfmå¯¹æ¯”ï¼Œæ²¡æœ‰è·Ÿä¼ ç»Ÿçš„SLAMæ–¹æ³•å¯¹æ¯”ï¼Œè€Œä¸”éªŒè¯çš„åºåˆ—ä¹Ÿæ˜¯éå¸¸å°‘çš„

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/å¾®ä¿¡æˆªå›¾_20250322161331.png" width="80%" />
<figcaption>  
</figcaption>
</div>



## æ€»ç»“è¿™å‡ ç¯‡å·¥ä½œ
ç›®å‰è¿™å‡ ç¯‡diffusionçš„å·¥ä½œï¼Œé™¤äº†åšfeature matchingæ˜¯æ¯”è¾ƒmake senseä»¥å¤–ï¼Œå…¶ä»–åŸºæœ¬æ˜¯ç¡¬è¦æŠŠåˆ«çš„å¯ä»¥ç‹¬ç«‹å®Œæˆtaskçš„æ¡†æ¶æ”¹æˆdiffusionæ¥åšã€‚æ¯”å¦‚æœ€ç»å…¸çš„å°±æ˜¯ä¸Šé¢çš„Posediffusionã€‚ä¸è¿‡ä¹Ÿæ˜¯æä¾›äº†è§£å†³é—®é¢˜çš„é¢å¤–çš„æ–°æ€è·¯ã€‚æœŸå¾…åç»­æœ‰æ›´åŠ make senseçš„diffusion-based SLAMå·¥ä½œå§~