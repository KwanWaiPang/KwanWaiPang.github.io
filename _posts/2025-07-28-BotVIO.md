---
layout: post
title: "论文复现及阅读笔记——《BotVIO: A Lightweight Transformer-Based Visual–Inertial Odometry for Robotics》"
date:   2025-07-28
tags: [SLAM, Deep Learning]
comments: true
author: kwanwaipang
toc: true
---


<!-- * 目录
{:toc} -->


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# 引言

本博文对于 2025 TRO的Transformer-based VIO工作进行复现，测试效果。
本博文仅供本人学习记录用~

* [paper](https://ieeexplore.ieee.org/abstract/document/11024235)
* [code](https://github.com/wenhuiwei-ustc/BotVIO)
* 基于Transformer的SLAM工作调研：[paper list](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM)
* 基于Learning的SLAM工作调研：[paper list](https://github.com/KwanWaiPang/Awesome-Learning-based-VO-VIO)
* 本博文复现过程采用的代码及代码注释（如有）：[My github repository](https://github.com/R-C-Group/BotVIO)

# 理论解读





# 代码复现

## 配置测试

```sh
git clone https://github.com/R-C-Group/BotVIO.git  --recursive

conda create -n botvio python=3.10
conda activate botvio

conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
pip install timm==0.4.12
pip install matplotlib
pip install gdown
pip install scipy
pip install scikit-image
pip install einops
pip install opencv-python
```

Data Preparation:采用KITTI数据集(注意要留有空间)

```sh
cd data
source data_prep.sh 
```

然后下载预训练模型[link](https://drive.google.com/drive/folders/1D-CpdPKyOwRMFlU-sp0dhslvIBmx9oxf?usp=drive_link),并且放在`pretrain_models`路径下

~~~
cd ./pretrain_models
python download.py
~~~

计算pose的结果：

```sh
conda activate botvio

python ./evaluations/eval_odom.py #这句运行需要创建一个results文件，并且运行了没有任何结果输出～～～

# CUDA_VISIBLE_DEVICES=0 PYTHONPATH=/home/gwp/BotVIO/ python ./evaluations/evaluate_pose_vo.py --load_weights_folder=pretrain_models  --data_path=data
# Please modify '--data_path' in the options.py file to specify your dataset path. 
# Additionally, update the pose embedding data type to float16 in PositionalEncodingFourier function within the depth encoder.py file.  
# In addtion, comment out the fully connected (FC) layer in the pose_encoder.py.
# 注意vio中有一个额外的全链接层，如果运行vo的时候要注释

#需要先创建空的文件夹results
CUDA_VISIBLE_DEVICES=0 PYTHONPATH=/home/gwp/BotVIO/ python ./evaluations/evaluate_pose_vio.py --load_weights_folder=pretrain_models  --data_path=data --eval_data_path=data
# Please modify '--data_path' in the options.py file to specify your dataset path. Additionally, update the pose embedding data type to float16 in PositionalEncodingFourier function within the depth encoder.py file.
```

运行效果结果：

<div align="center">
  <img src="https://github.com/R-C-Group/BotVIO/raw/main/results/WX20250728-174730.png" width="100%" />
<figcaption>  
</figcaption>
</div>




