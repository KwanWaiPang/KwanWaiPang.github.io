---
layout: post
title: "论文阅读及实验复现之——《E-3DGS: Event-Based Novel View Rendering of Large-Scale Scenes Using 3D Gaussian Splatting》"
date:   2025-04-14
tags: [Event-based Vision, Deep Learning]
comments: true
author: kwanwaipang
toc: true
---


<!-- * 目录
{:toc} -->


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# 引言
3DGS在新视觉合成上受到广泛的关注，而基于事件相机也有不少3DGS相关的工作。
本博文对于 2025 3DV的这个event-based 3DGS工作进行复现，测试效果。
本博文仅供本人学习记录用~

* [paper](https://arxiv.org/pdf/2502.10827)
* [website](https://4dqv.mpi-inf.mpg.de/E3DGS/)
* [code](https://github.com/sohaib023/E-3DGS)
* 基于3DGS的SLAM工作调研：[paper list](https://github.com/KwanWaiPang/Awesome-3DGS-SLAM)
* 本博文复现过程采用的代码及代码注释（如有）：[My github repository](https://github.com/KwanWaiPang/E-3DGS)



# 理论解读
首先开篇还是老套路，提到的是事件相机在运动模糊及特殊光照条件下比传统相机有优势（不过还是没有实验验证在fast motion或者hdr环境下与image baseline对比）。
虽然现有不少event-based 3DGS的工作，不过还是以面向前端或以物体为中心的场景，因此，作者还是宣称自己是首次提出基于3DGS的event-based 新视觉合成。该方法可以重构大型环境并且保证高的视觉质量。

论文的主要贡献点有：
1. 采用的是color event camera（应该是由拜尔滤波器产生的带颜色事件），因此可以实现带颜色的彩色渲染。
2.  初始化（frustum-based initialization）、自适应的事件窗口、3D gaussian的正则化，camera pose refinement等等的策略设计。
3. 开源了一个数据集（包含仿真数据以及真实数据）[E-3DGS-Dataset](https://drive.google.com/drive/folders/1yRlg33ttbhm27EeyCpZTxrWlkX3C5bz1)



# 实验复现




