---
layout: post
title: "论文学习及实验笔记之——《VGGT: Visual Geometry Grounded Transformer》"
date:   2025-03-18
tags: [Deep Learning]
comments: true
author: kwanwaipang
toc: true
---


<!-- * 目录
{:toc} -->


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# 引言
之前博客对Transformer以及基于Transformer的SLAM进行了解读。而最近CVPR2025新开源了VGGT可以实现推理场景中的所有的关键三维属性（如：相机的内参与外参，point map，深度图，3D点跟踪）。

为此，写下本博文记录阅读及测试过程，本博文仅供本人学习记录用~

相关的资料：
* [paper](https://arxiv.org/pdf/2503.11651)
* [Github](https://github.com/facebookresearch/vggt)
* [Awesome Transformer-based SLAM](https://github.com/KwanWaiPang/Awesome-Transformer-based-SLAM)
* [Paper Survey之——Awesome Transformer-based SLAM](https://kwanwaipang.github.io/Transformer_SLAM/)
* [What is Transformer? Form NLP to CV](https://kwanwaipang.github.io/Transformer/)


# 理论解读

VGGT是一个 large feed-forward transformer，通过输入高达数百张图片，一次（少于1秒）预测出所有图片的三维属性（相机的内参与外参，point map，深度图，3D点跟踪）



# 实验测试

* 本测试采用的代码及后续的注释（如有）均在[Github](https://github.com/KwanWaiPang/vggt)

