---
layout: post
title: "实验笔记之——MASt3R-SLAM"
date:   2025-02-26
tags: [Deep Learning, SLAM]
comments: true
author: kwanwaipang
toc: true
---


<!-- * 目录
{:toc} -->


# 引言

在MASt3R提供的a two-view 3D reconstruction and matching prior基础上，作者通过引入有效的pointmap matching, camera tracking and local fusion, graph construction and loop closure, 以及second-order global optimisation，提出了MASt3R-SLAM，一个实时的单目稠密SLAM系统（可以实现15FPS的定位及稠密三维重建）。 同时，MASt3R原本就不依赖于camera的model，那么就可以实现reconstructing scenes with generic, time-varying camera models（也就是demo中zoom in zoom out的情况下的稳定三维重建）.当然要达到在多个benchmark上的SOTA performance，还是需要“已知的标定参数”。

之前[博客](https://kwanwaipang.github.io/File/Blogs/Poster/MASt3R-SLAM.html)已经将DUSt3R以及MASt3R进行了介绍以及测试。
本博文对MASt3R-SLAM进行深入的学习~

~~~
@article{murai2024mast3r,
  title={MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors},
  author={Murai, Riku and Dexheimer, Eric and Davison, Andrew J},
  journal={arXiv preprint arXiv:2412.12392},
  year={2024}
}
~~~

本博客为本人学习记录用~


# 配置过程
* 配置与测试过程采用的代码为[MASt3R-SLAM_comment](https://github.com/KwanWaiPang/MASt3R-SLAM_comment)

```bash
# git clone --recurse-submodules https://github.com/rmurai0610/MASt3R-SLAM.git
# rm -rf .git

conda create -n mast3r-slam python=3.11
conda activate mast3r-slam
# conda remove --name mast3r-slam --all

# 查看cuda版本来决定安装哪个pytorch
nvcc --version

# CUDA 12.1 (12.2应该也是用这个，A100)
conda install pytorch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 pytorch-cuda=12.1 -c pytorch -c nvidia

#CUDA11.7 （3090）
conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia

pip install -e thirdparty/mast3r
pip install -e thirdparty/in3d
pip install --no-build-isolation -e .
```

# 设置checkpoint

应该就是下载系列的权重文件

```bash
mkdir -p checkpoints/
wget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric.pth -P checkpoints/
wget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_trainingfree.pth -P checkpoints/
wget https://download.europe.naverlabs.com/ComputerVision/MASt3R/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric_retrieval_codebook.pkl -P checkpoints/
```

# 下载数据集
此处直接用之前下载的Euroc数据集`/home/gwp/AirIMU/Euroc_dataset`

```bash
# TUM-RGBD Dataset
bash ./scripts/download_tum.sh

# 7-Scenes Dataset
bash ./scripts/download_7_scenes.sh

# EuRoC Dataset
bash ./scripts/download_euroc.sh

# ETH3D SLAM Dataset
bash ./scripts/download_eth3d.sh
```

注意在下载的脚本里面会对数据集进行创建文件夹然后规定命名，比如`euroc`，而代码中会寻找`euroc`来确定是否目标数据集，因此如果下载的数据文件命名不一样，需要修改文件名或者代码~

当然也可以进行软链接:

```bash
ln -s /home/gwp/AirIMU/Euroc_dataset /home/gwp/MASt3R-SLAM/datasets/euroc
```

<div align="center">
  <img src="https://github.com/KwanWaiPang/MASt3R-SLAM_comment/raw/main/media/微信截图_20250226172338.png" width="30%" />
<figcaption>  
</figcaption>
</div>

# Debug过程
EuRoC Dataset，bash运行的应该就是分别采用带标定参数或者不带标定参数的

```bash
conda activate mast3r-slam
# bash ./scripts/eval_euroc.sh 
# bash ./scripts/eval_euroc.sh --no-calib

# 直接采用py脚本运行不带标定参数的
CUDA_VISIBLE_DEVICES=3 python main.py --dataset datasets/euroc/MH_01_easy/ --no-viz --config config/eval_no_calib.yaml
CUDA_VISIBLE_DEVICES=3 python main.py --dataset datasets/euroc/V1_03_difficult --config config/eval_no_calib.yaml
CUDA_VISIBLE_DEVICES=3 python main.py --dataset datasets/tum/rgbd_dataset_freiburg1_room/ --config config/calib.yaml
```

但是会报错`RuntimeError: CUDA error: no kernel image is available for execution on the device`，也提了[issue](https://github.com/rmurai0610/MASt3R-SLAM/issues/12)。最终在[issue](https://github.com/rmurai0610/MASt3R-SLAM/issues/4)中发现了类似的问题，然后根据作者提供的建议进行修改~

这个问题应该是CUDA compute capability跟编译要用的不一样导致的。
先查看一下`nvidia-smi --query-gpu=compute_cap --format=csv`发现CUDA compute capability是8.0

<div align="center">
  <img src="https://github.com/KwanWaiPang/MASt3R-SLAM_comment/raw/main/media/微信截图_20250226194554.png" width="60%" />
<figcaption>  
</figcaption>
</div>

那么就将`setup.py`中的`"-gencode=arch=compute_86,code=sm_86",`先改为80即可

<div align="center">
  <img src="https://github.com/KwanWaiPang/MASt3R-SLAM_comment/raw/main/media/微信截图_20250226201144.png" width="60%" />
<figcaption>  
</figcaption>
</div>

重新编译`pip install --no-build-isolation -e .`,再次运行就work!!!

至此，如果不需要可视化的话应该就没有其他问题了。但是如果要进行可视化，运行代码会发现libGL打不开

<div align="center">
  <img src="https://github.com/KwanWaiPang/MASt3R-SLAM_comment/raw/main/media/微信截图_20250226200040.png" width="50%" />
<figcaption>  
</figcaption>
</div>

从下面路径可以找到`/lib/x86_64-linux-gnu/dri/swrast_dri.so`然后将其进行复制到`/usr/lib/dri`中
```bash
sudo cp /lib/x86_64-linux-gnu/dri/swrast_dri.so /usr/lib/dri

# 当然软链接一下也是可以的，注意需要创建文件夹dri
sudo mkdir dri
ln -s /lib/x86_64-linux-gnu/dri/swrast_dri.so /usr/lib/dri
```

接下来又出现新的错误：

~~~
libGL error: MESA-LOADER: failed to open swrast: /home/gwp/miniconda3/envs/mast3r-slam/bin/../lib/libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /lib/x86_64-linux-gnu/libLLVM-15.so.1) (search paths /usr/lib/x86_64-linux-gnu/dri:\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)
libGL error: failed to load driver: swrast
~~~

应该是缺少conda识别的GCC，执行安装：

```bash
 conda install -c conda-forge gcc
```
接下来就完全可以正常运行了~


PS：也尝试了在cuda11.7的3090上配置也是正常的（而我的3090上的就是8.6因此setup.py不需要更改）~

之前有同行在[issue](https://github.com/rmurai0610/MASt3R-SLAM/issues/9)提到到对于pytorch<2.5.0在运行`pip install --no-build-isolation -e .`的时候可能会报错。
对应的`linalg_norm`部分进行修改即可~


# 实验效果
见下面视频


<div align="center">
<iframe width="80%" height="400" src="//player.bilibili.com/player.html?isOutside=true&aid=114070355184394&bvid=BV1ctP7epEWo&cid=28590016190&p=1&autoplay=0" title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>


<div align="center">
<iframe width="80%" height="400" src="//player.bilibili.com/player.html?isOutside=true&aid=114070422294380&bvid=BV1AHP7e4EZt&cid=28590342717&p=1&autoplay=0" title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>




# 参考资料
* [MASt3R-SLAM paper](https://arxiv.org/pdf/2412.12392)
* [MASt3R-SLAM website](https://edexheim.github.io/mast3r-slam/)
* [MASt3R-SLAM github](https://github.com/rmurai0610/MASt3R-SLAM)