---
layout: post
title: "实验复现之——《MAC-VO: Metrics-aware Covariance for Learning-based Stereo Visual Odometry》"
date:   2025-05-30
tags: [SLAM, Deep Learning]
comments: true
author: kwanwaipang
toc: true
---


<!-- * 目录
{:toc} -->


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# 引言

ICRA2025的Best Conference Paper Award开源了，对其进行测试，写下本博文作为学习记录用~

* [paper](https://arxiv.org/pdf/2409.09479)
* [website](https://mac-vo.github.io/)
* [code](https://github.com/MAC-VO/MAC-VO)
* 本博文复现过程采用的代码及代码注释（如有）：[My github repository](https://github.com/R-C-Group/MAC-VO)


# 理论学习
MAC-VO的核心在于其提出的Metrics-aware Covariance。利用学习到的度量感知匹配不确定性来执行两个主要任务：选择关键点和在姿态图优化中加权残差（也就是对于检测出的关键点的空间协方差的建模）。

此外，MAC-VO除了定位以外也可以增量式构建map。其主体框架包括：
1. uncertainty-aware matching network,实现双目特征的匹配以及对于Metrics-aware uncertainty进行建模

<div align="center">
  <img src="../images/微信截图_20250530145010.png" width="60%" />
<figcaption>  
</figcaption>
</div>

2. Uncertainty Aware Keypoint Selector。进行鲁棒的特征点选择，其包括了三个模块来逐步选择鲁棒的特征点。

<div align="center">
  <img src="../images/微信截图_20250530145255.png" width="90%" />
<figcaption>  
</figcaption>
</div>

3. Metrics Aware Spatial Covariance。对于每个特征点所估算出来的光流以及不确定的深度，会投影到3D空间。而这个过程将会保留了尺度信息，因此可以获得针对每个特征点的Metrics Aware 3D协方差。而针对双目匹配可能带来的误差，作者对这个uncertainty进行建模获得其协方差

<div align="center">
  <img src="../images/微信截图_20250530145718.png" width="90%" />
<figcaption>  
</figcaption>
</div>

直观的理解就是，首先因为是双目，因此是宣称Metrics-aware ，其次，通过网络来进行双目的特征匹配及光流计算。并且通过三个filter的设计来对特征点进行选择（比如说：DPVO中patch是random sample的，此处则为有针对性的选择）。最后再进行Pose Graph 优化（也就是重投影误差或者叫BA）。而求解的过程用时`PyPose`

<div align="center">
  <img src="../images/微信截图_20250530150051.png" width="90%" />
<figcaption>  
</figcaption>
</div>

而从论文的实验结果看，跟DPVO，ORB-SLAM3， DROID-SLAM，MASt3R-SLAM这些SOTA比都有所提升：

<div align="center">
  <img src="../images/微信截图_20250530150241.png" width="90%" />
<figcaption>  
</figcaption>
</div>


# 实验测试
## 配置过程

```bash
git clone https://github.com/R-C-Group/MAC-VO.git --recursive
# rm -rf .git

conda create -n macvo python=3.10.11
conda activate macvo
#  conda remove --name macvo --all

pip install -r requirements.txt

```

* 下载模型

```bash
$ mkdir Model
$ wget -O Model/MACVO_FrontendCov.pth https://github.com/MAC-VO/MAC-VO/releases/download/model/MACVO_FrontendCov.pth
$ wget -O Model/MACVO_posenet.pkl https://github.com/MAC-VO/MAC-VO/releases/download/model/MACVO_posenet.pkl
```

* 下载数据

```bash
pip install gdown

gdown https://drive.google.com/uc?id=标识符

mkdir Dataset
gdown https://drive.google.com/uc?id=1kCTNMW2EnV42eH8g2STJHcVWEbVKbh_r

```

然后修改`Config/Experiment/MACVO/MACVO_example.yaml`中的数据路径`Data: !include ../../Sequence/TartanAir_example.yaml`也就是对应的`root`
然后运行代码如下：

```bash
python3 MACVO.py --odom Config/Experiment/MACVO/MACVO_example.yaml --data Config/Sequence/TartanAir_example.yaml

```

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/assets/微信截图_20250530122713.png" width="80%" />
<figcaption>  
</figcaption>
</div>

## 实验效果

* 接下来进行可视化以及验证结果

```bash
# 验证精度
python -m Evaluation.EvalSeq --spaces SPACE_0, [SPACE, ...]
python -m Evaluation.EvalSeq --spaces Results/MACVO@abf001/05_30_121311

# 画轨迹
python -m Evaluation.PlotSeq --spaces SPACE_0, [SPACE, ...]
python -m Evaluation.PlotSeq --spaces Results/MACVO@abf001/05_30_121311

```

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/assets/微信截图_20250530122943.png" width="80%" />
<figcaption>  
</figcaption>
</div>

<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Combined_ROEcdf.png" width="100%" />
        Combined_ROEcdf
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Combined_RTEcdf.png" width="100%" />
        Combined_RTEcdf
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Combined_rrel.png" width="100%" />
<figcaption>  
Combined_rrel
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Combined_trel.png" width="100%" />
<figcaption>  
Combined_trel
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/MACVO@abf001_RotationErr.png" width="100%" />
<figcaption>  
MACVO@abf001_RotationErr
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/MACVO@abf001_TranslationErr.png" width="100%" />
<figcaption>  
MACVO@abf001_TranslationErr
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/MACVO@abf001_Trajectory.png" width="100%" />
<figcaption>  
MACVO@abf001_Trajectory
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Ref_Compare.png" width="100%" />
<figcaption>  
Ref_Compare
</figcaption>
</div>

* 而对于mapping module，其不会执行pose的优化，因此需要先获取tracking后再运行mapping部分

```bash
python MACVO.py --odom ./Config/Experiment/MACVO/MACVO_mapping.yaml --data ./Config/Sequence/TartanAir_example.yaml
# --data ./Config/Sequence/TartanAir_abandonfac_001.yaml
#将其中的gtFlow设置为false，由于作者提供的sample数据并没有光流

#注意，需要对./Config/Experiment/MACVO/MACVO_mapping.yaml中的motion > args 放置pose文件路径

```
运行完mapping后效果如下：

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/assets/微信截图_20250530135504.png" width="80%" />
<figcaption>  
</figcaption>
</div>

接下来进行可视化。3D可视化采用的为[the Rerun](https://rerun.io/),包括了相机姿态、点云以及轨迹。
* 采用MobaXterm
* 作者github中给出的可视化似乎不可用，改为用下面命令可以边运行边可视化，但是对该插件不太熟悉，就没录视频了~

```bash
conda activate macvo

python MACVO.py --odom ./Config/Experiment/MACVO/MACVO_mapping.yaml --data ./Config/Sequence/TartanAir_example.yaml --useRR
```

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/assets/微信截图_20250530141921.png" width="80%" />
<figcaption>  
</figcaption>
</div>