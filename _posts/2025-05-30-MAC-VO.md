---
layout: post
title: "实验复现之——《MAC-VO: Metrics-aware Covariance for Learning-based Stereo Visual Odometry》"
date:   2025-05-30
tags: [SLAM, Deep Learning]
comments: true
author: kwanwaipang
toc: true
---


<!-- * 目录
{:toc} -->


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# 引言

ICRA2025的Best Conference Paper Award开源了，对其进行测试，写下本博文作为学习记录用~

* [paper](https://arxiv.org/pdf/2409.09479)
* [website](https://mac-vo.github.io/)
* [code](https://github.com/MAC-VO/MAC-VO)
* 本博文复现过程采用的代码及代码注释（如有）：[My github repository](https://github.com/R-C-Group/MAC-VO)




# 实验测试
## 配置过程

```bash
git clone https://github.com/R-C-Group/MAC-VO.git --recursive
# rm -rf .git

conda create -n macvo python=3.10.11
conda activate macvo
#  conda remove --name macvo --all

pip install -r requirements.txt

```

* 下载模型

```bash
$ mkdir Model
$ wget -O Model/MACVO_FrontendCov.pth https://github.com/MAC-VO/MAC-VO/releases/download/model/MACVO_FrontendCov.pth
$ wget -O Model/MACVO_posenet.pkl https://github.com/MAC-VO/MAC-VO/releases/download/model/MACVO_posenet.pkl
```

* 下载数据

```bash
pip install gdown

gdown https://drive.google.com/uc?id=标识符

mkdir Dataset
gdown https://drive.google.com/uc?id=1kCTNMW2EnV42eH8g2STJHcVWEbVKbh_r

```

然后修改`Config/Experiment/MACVO/MACVO_example.yaml`中的数据路径`Data: !include ../../Sequence/TartanAir_example.yaml`也就是对应的`root`
然后运行代码如下：

```bash
python3 MACVO.py --odom Config/Experiment/MACVO/MACVO_example.yaml --data Config/Sequence/TartanAir_example.yaml

```

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/assets/微信截图_20250530122713.png" width="80%" />
<figcaption>  
</figcaption>
</div>

## 实验效果

* 接下来进行可视化以及验证结果

```bash
# 验证精度
python -m Evaluation.EvalSeq --spaces SPACE_0, [SPACE, ...]
python -m Evaluation.EvalSeq --spaces Results/MACVO@abf001/05_30_121311

# 画轨迹
python -m Evaluation.PlotSeq --spaces SPACE_0, [SPACE, ...]
python -m Evaluation.PlotSeq --spaces Results/MACVO@abf001/05_30_121311

```

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/assets/微信截图_20250530122943.png" width="80%" />
<figcaption>  
</figcaption>
</div>

<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Combined_ROEcdf.png" width="100%" />
        Combined_ROEcdf
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Combined_RTEcdf.png" width="100%" />
        Combined_RTEcdf
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Combined_rrel.png" width="100%" />
<figcaption>  
Combined_rrel
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Combined_trel.png" width="100%" />
<figcaption>  
Combined_trel
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/MACVO@abf001_RotationErr.png" width="100%" />
<figcaption>  
MACVO@abf001_RotationErr
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/MACVO@abf001_TranslationErr.png" width="100%" />
<figcaption>  
MACVO@abf001_TranslationErr
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/MACVO@abf001_Trajectory.png" width="100%" />
<figcaption>  
MACVO@abf001_Trajectory
</figcaption>
</div>

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/Results/Ref_Compare.png" width="100%" />
<figcaption>  
Ref_Compare
</figcaption>
</div>

* 而对于mapping module，其不会执行pose的优化，因此需要先获取tracking后再运行mapping部分

```bash
python MACVO.py --odom ./Config/Experiment/MACVO/MACVO_mapping.yaml --data ./Config/Sequence/TartanAir_example.yaml
# --data ./Config/Sequence/TartanAir_abandonfac_001.yaml
#将其中的gtFlow设置为false，由于作者提供的sample数据并没有光流

#注意，需要对./Config/Experiment/MACVO/MACVO_mapping.yaml中的motion > args 放置pose文件路径

```
运行完mapping后效果如下：

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/assets/微信截图_20250530135504.png" width="80%" />
<figcaption>  
</figcaption>
</div>

接下来进行可视化。3D可视化采用的为[the Rerun](https://rerun.io/),包括了相机姿态、点云以及轨迹。
* 采用MobaXterm
* 作者github中给出的可视化似乎不可用，改为用下面命令可以边运行边可视化，但是对该插件不太熟悉，就没录视频了~

```bash
conda activate macvo

python MACVO.py --odom ./Config/Experiment/MACVO/MACVO_mapping.yaml --data ./Config/Sequence/TartanAir_example.yaml --useRR
```

<div align="center">
  <img src="https://github.com/R-C-Group/MAC-VO/raw/main/assets/微信截图_20250530141921.png" width="80%" />
<figcaption>  
</figcaption>
</div>