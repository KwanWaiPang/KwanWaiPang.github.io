---
layout: post
title: "论文实验笔记之——《FAPP: Fast and Adaptive Perception and Planning for UAVs in Dynamic Cluttered Environments》"
date:   2026-01-07
tags: [LiDAR]
comments: true
author: kwanwaipang
toc: true
excerpt: "" # 【指定摘要内容】
---


<!-- * 目录
{:toc} -->

* [PDF](https://arxiv.org/pdf/2312.08743)
* [Github源码](https://github.com/arclab-hku/FAPP)
* 本博文复现过程采用的代码及代码注释（如有）：[My github repository](https://github.com/R-C-Group/-Fast-and-Adaptive-Perception-and-Planning)


# 理论解读




# 实验复现

# #安装配置

```bash
sudo apt install python3-catkin-tools python3-osrf-pycommon

git clone git@github.com:R-C-Group/-Fast-and-Adaptive-Perception-and-Planning.git
cd FAPP 
catkin build

# source ~/catkin_ws/FAPP/devel/setup.bash
```

安装tmux

```bash
# install tmux
sudo apt install tmux
sudo apt install tmuxp
# kill a session (for example)
tmux kill-session -t fapp
```

运行demo

```bash
tmuxp load quick_start.yaml 
```

运行后则可以加载环境，并且环境中有移动物体/静态物体，通过设置`3D Nav Goal`可以实现导航及规划，同时也实时估算运动物体的速度。

<div align="center">
  <img src="https://github.com/R-C-Group/-Fast-and-Adaptive-Perception-and-Planning/raw/main/fig/微信截图_20251218140211.png" width="90%" />
<figcaption>  
</figcaption>
</div>


实时性测试效果如下：5个物体，点云聚类耗时1.2ms，跟踪耗时1.8ms。

<div align="center">
  <img src="https://github.com/R-C-Group/-Fast-and-Adaptive-Perception-and-Planning/raw/main/fig/微信截图_20251218135210.png" width="90%" />
<figcaption>  
</figcaption>
</div>

内存消耗情况如下：
* 处理器是11th Gen Intel(R) Core(TM) i7-11800H @ 2.30GHz (2.30 GHz)，机带RAM为32.0 GB
* 【CPU占用情况】
  * rviz (56.0% CPU): 占用了大约半个核心。
  * mapping_node (52.3% CPU): 建图节点。占用半个核心也属于正常范围。
  * fapp_planner_no (11.0% CPU): 路径规划节点。占用较低，运行稳定。
* 【内存占用情况】
  * 系统识别到的总内存约为 16GB。
  * mapping_node	383.8 MiB，fapp_planner	144.6 MiB


<div align="center">
  <img src="https://github.com/R-C-Group/-Fast-and-Adaptive-Perception-and-Planning/raw/main/fig/微信截图_20251218135422.png" width="90%" />
<figcaption>  
</figcaption>
</div>


* 通过Antigravity打开项目（选择打开文件）：

```bash
\\wsl$\Ubuntu-20.04\home\kwanwaipang\catkin_ws\FAPP\src
```

* 添加[livox_ros_driver2](https://github.com/Livox-SDK/livox_ros_driver2/tree/master):
* 此前需要安装[SDK](https://github.com/Livox-SDK/Livox-SDK2/blob/master/README.md)

```bash
# 安装SDK
git clone https://github.com/Livox-SDK/Livox-SDK2.git
cd ./Livox-SDK2/
mkdir build
cd build
cmake .. && make -j
sudo make install

# 安装驱动
# ./build.sh ROS1 #这个脚本不仅会编译，还会将 package.xml 和 CMakeLists.txt 重定向/重写为符合 ROS 1 标准的文件。
cd /home/kwanwaipang/catkin_ws/FAPP/src/livox_ros_driver2
# 确保使用的是 ROS1 的包描述文件
cp -f package_ROS1.xml package.xml
cd /home/kwanwaipang/catkin_ws/FAPP/
# 重新初始化并编译（指定参数）
catkin build livox_ros_driver2 -DROS_EDITION=ROS1

# 然后重新执行,编译全部
# 2. 编译整个工作空间，并确保 ROS_EDITION 参数一直有效
catkin config --append-args -DROS_EDITION=ROS1
catkin build
```

## 真机测试

此处选择录制rosbag,注意对应的topic情况如下:

<div align="center">
  <img src="https://github.com/R-C-Group/-Fast-and-Adaptive-Perception-and-Planning/raw/main/fig/微信图片_20260107105429.png" width="90%" />
<figcaption>  
</figcaption>
</div>

```bash
source devel/setup.bash
# roslaunch so3_quadrotor_simulator simulator_example.launch 
roslaunch mot_mapping bag_mapping.launch
```


<div align="center">
  <img src="https://github.com/R-C-Group/-Fast-and-Adaptive-Perception-and-Planning/raw/main/fig/微信截图_20260107113852.png" width="90%" />
<figcaption>  
</figcaption>
</div>


# 参考资料
* [论文阅读-Fast and Adaptive Perception and Planning for UAVs in Dynamic Cluttered Environments](https://blog.csdn.net/qq_55653355/article/details/154788556)
