---
layout: post
title: "论文阅读及复现笔记之——《Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass》"
date:   2025-03-06
tags: [SLAM,Deep Learning]
comments: true
author: kwanwaipang
toc: true
excerpt: "" # 【指定摘要内容】
---


<!-- * 目录
{:toc} -->


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# 引言
由Meta和University of Michigan发表的CVPR2025工作《Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass》实现1000多幅图像的3D重建。基于DUSt3R的多视图泛化，通过并行处理多个视图实现高效且可扩展的3D重建，速度高达 250 FPS（DUSt3R是0.78 FPS，Spann3R是65.49 FPS），并可在一次前向传递中处理 1000+ 张图像。
为此本博文对该工作进行学习并且复现，本博文仅供本人学习记录用~

* [paper](https://arxiv.org/pdf/2501.13928)
* [github](https://github.com/facebookresearch/fast3r)
* [website](https://fast3r-3d.github.io/)
* [DUSt3R与MASt3R学习博客](https://kwanwaipang.github.io/File/Blogs/Poster/MASt3R-SLAM.html)
* [MASt3R-SLAM实验笔记](https://kwanwaipang.github.io/MASt3R-SLAM/)


<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->
# 理论学习

Fast3R应该是在DUSt3R上的改进，所提出的基于Transformer的结构可以在单次前向递推的时候同时处理N张图片，进而不需要迭代对齐（iterative alignment），那么既然是基于DUSt3R的改进，那么应该就是以三维重建为主，同时可估算相机的pose，并且不需要已知的相机的内参和外参（pose）。

DUSt3R是直接从RGB图像预测3D结构（无需图像的内参与外参），它把成对的重建（pairwise reconstruction）问题看成是对pointmaps的回归，并不需要相机投射投影模型。但同时，DUSt3R从原理上显示了它需要两张图像输入，而对于多张图片输入的情况，DUSt3R应该是对每对的pointmaps进行金酸然后再运行global alignment的优化处理，从而导致计算量极大。

~~~
PS：测试DUSt3R的时候会发现，比如输入10张图像，要进行90次推理运算（应该是90对图片），推理运算后，在执行全局优化。

而Fast3R则是：processes multiple images in parallel, allowing N images to be reconstructed in a single forward pass.

Spann3R应该也是有点类似的思路，增量式构建环境利用一对滑动窗口网络（sliding window network），但是对于窗口以外的是不能联合优化，进而会存在累积误差。而Fast3R all in的策略，不管输入的image多少，一起处理了
~~~

Fast3R的结构如下所示。整个模块分为image encoding，fusion transformer以及pointmap decoding。
* image encoding跟DUSt3R一样，采用CroCo ViT
* fusion transformer是计算量最大的一部分，采用12层的transformer， takes the concatenated encoded image patches from all views and performs all-to-all self-attention.
* pointmap decoding将所有的tokens映射到各自的local 和global pointmaps上

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/微信截图_20250306142014.png" width="60%" />
<figcaption>  
</figcaption>
</div>

Fast3R是预测pointmap，所谓的pointmaps其实就是一张图片的每个pixel的3D位置，而预测的pointmap包括局部以及global的，同时还有对应的confidence maps

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/微信截图_20250306145810.png" width="60%" />
<figcaption>  
</figcaption>
</div>
其loss如下：
<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/微信截图_20250306150105.png" width="60%" />
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/微信截图_20250306150140.png" width="60%" />
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/微信截图_20250306150113.png" width="60%" />
<figcaption>  
这部分应该跟DUSt3R和MASt3R差不多
</figcaption>
</div>

采用真实场景中扫描到的laser scan point作为真值



<!-- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! -->

# 复现效果

作者做了个网页的[demo](https://fast3r.ngrok.app/)可以实现上传图片后实时可视化三维重建的效果，下面是操作流程：
<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://github.com/KwanWaiPang/fast3r_comment/raw/main/assets/fast3r_demo_upload.gif" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://github.com/KwanWaiPang/fast3r_comment/raw/main/assets/fast3r_demo_control.gif" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

此外，还提供了比如可视化heatmap，逐帧处理以及渲染成GIF等功能

<div align="center">
  <img src="https://github.com/KwanWaiPang/fast3r_comment/raw/main/assets/fast3r_demo_coloring.gif" width="60%" />
<figcaption>  
</figcaption>
</div>

而作者在网页上也提供了一系列的样例，
<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/images/微信截图_20250306101608.png" width="60%" />
<figcaption>  
</figcaption>
</div>

用样例测试的效果如下：
<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/visualization.gif" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/visualization (1).gif" width="100%" />
      </td>
    </tr>
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/visualization (2).gif" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/visualization (3).gif" width="100%" />
      </td>
    </tr>
  </table>
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/visualization (4).gif" width="80%" />
  <figcaption>
  </figcaption>
</div>

此外，也尝试了用自采的数据进行测试。
首先采用一张图

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/mydesk_1.gif" width="60%" />
<figcaption>  
单图片的重建效果
</figcaption>
</div>

接下来分别用下面两种双视角的情况测试
<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/mydesk_2_1.png" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/mydesk_2_2.png" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

重建的效果如下：

<div align="center">
  <table style="border: none; background-color: transparent;">
    <tr align="center">
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/mydesk_2_1.gif" width="100%" />
      </td>
      <td style="width: 50%; border: none; padding: 0.01; background-color: transparent; vertical-align: middle;">
        <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/mydesk_2_2.gif" width="100%" />
      </td>
    </tr>
  </table>
  <figcaption>
  </figcaption>
</div>

接下来采用多张图片看看效果

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/mydesk_7.gif" width="60%" />
<figcaption>  
7张图片的重建效果
</figcaption>
</div>

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/mydesk_16.gif" width="60%" />
<figcaption>  
16张图片的重建效果
</figcaption>
</div>

下面是视频可视化整个操作流程

<!-- <div align="center">
<iframe width="80%" height="400" src="//player.bilibili.com/player.html?isOutside=true&aid=114112818319035&bvid=BV1gHRFYcEWg&cid=28714797145&p=1&p=1&autoplay=0" title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div> -->
<div align="center" style="
  position: relative; 
  width: 80%; 
  height: 400px;
  margin: 0 auto;
  border-radius: 15px;
  background: url('https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif') center/contain no-repeat;
  ">
  <iframe width="100%" height="100%"
    src="//player.bilibili.com/player.html?isOutside=true&aid=114112818319035&bvid=BV1gHRFYcEWg&cid=28714797145&p=1&autoplay=0" 
    title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen  style="opacity: 0; transition: opacity 0.5s; border-radius: 15px;" onload="this.style.opacity='1'"
  ></iframe>
</div>


不过也尝试了下室外大场景，用的train数据集，但是效果就不如上面的测试序列了~

<div align="center">
  <img src="https://kwanwaipang.github.io/ubuntu_md_blog/Fast3R/train.gif" width="60%" />
<figcaption>  
</figcaption>
</div>

## DUSt3R VS. Fast3R

下面对比一下单张图片输入的情况下，DUSt3R与Fast3R的效果（相同的输入）

<div align="center" style="
  position: relative; 
  width: 80%; 
  height: 400px;
  margin: 0 auto;
  border-radius: 15px;
  background: url('https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif') center/contain no-repeat;
  ">
  <iframe width="100%" height="100%"
    src="//player.bilibili.com/player.html?isOutside=true&aid=114113942390119&bvid=BV1jVRwY5EhS&cid=28718533393&p=1&autoplay=0" 
    title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen  style="opacity: 0; transition: opacity 0.5s; border-radius: 15px;" onload="this.style.opacity='1'"
  ></iframe>
</div>

两张图片，视角相差较小：

<div align="center" style="
  position: relative; 
  width: 80%; 
  height: 400px;
  margin: 0 auto;
  border-radius: 15px;
  background: url('https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif') center/contain no-repeat;
  ">
  <iframe width="100%" height="100%"
    src="//player.bilibili.com/player.html?isOutside=true&aid=114113959169555&bvid=BV1V7RwYrEDg&cid=28718533929&p=1&autoplay=0" 
    title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen  style="opacity: 0; transition: opacity 0.5s; border-radius: 15px;" onload="this.style.opacity='1'"
  ></iframe>
</div>


两张图片，视角相差较大：

<div align="center" style="
  position: relative; 
  width: 80%; 
  height: 400px;
  margin: 0 auto;
  border-radius: 15px;
  background: url('https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif') center/contain no-repeat;
  ">
  <iframe width="100%" height="100%"
    src="//player.bilibili.com/player.html?isOutside=true&aid=114113942389675&bvid=BV1jVRwY5EZF&cid=28718534254&p=1&autoplay=0" 
    title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen  style="opacity: 0; transition: opacity 0.5s; border-radius: 15px;" onload="this.style.opacity='1'"
  ></iframe>
</div>


在大场景下的对比

<div align="center" style="
  position: relative; 
  width: 80%; 
  height: 400px;
  margin: 0 auto;
  border-radius: 15px;
  background: url('https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif') center/contain no-repeat;
  ">
  <iframe width="100%" height="100%"
    src="//player.bilibili.com/player.html?isOutside=true&aid=114113959169833&bvid=BV1V7RwYrEdE&cid=28718596135&p=1&autoplay=0" 
    title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen  style="opacity: 0; transition: opacity 0.5s; border-radius: 15px;" onload="this.style.opacity='1'"
  ></iframe>
</div>



<div align="center" style="
  position: relative; 
  width: 80%; 
  height: 400px;
  margin: 0 auto;
  border-radius: 15px;
  background: url('https://kwanwaipang.github.io/File/Representative_works/loading-icon.gif') center/contain no-repeat;
  ">
  <iframe width="100%" height="100%"
    src="//player.bilibili.com/player.html?isOutside=true&aid=114113959231505&bvid=BV1v7RwYrENj&cid=28718534617&p=1&autoplay=0" 
    title="Bilibili video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen  style="opacity: 0; transition: opacity 0.5s; border-radius: 15px;" onload="this.style.opacity='1'"
  ></iframe>
</div>

